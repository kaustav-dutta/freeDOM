{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '/tf/localscratch/weldert/freeDOM/' not in sys.path:\n",
    "    sys.path.append('/tf/localscratch/weldert/freeDOM/')\n",
    "    #sys.path.append('/localscratch/weldert/freeDOM/')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" #\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from freedom.toy_model import toy_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import dragoman as dm\n",
    "import pickle\n",
    "from types import SimpleNamespace\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14 \n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model.toy_experiment(detector_xs=np.linspace(-5, 5, 11), t_std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_x_src = 2.1\n",
    "example_b_src = 1.1\n",
    "example_N_src = 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(x_src=example_x_src, b=example_b_src, N_src=example_N_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid scan\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-2, 2, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "g = {}\n",
    "g['dom_hit_term'] = np.empty(x.shape)\n",
    "g['dom_charge_terms'] = np.empty(x.shape)\n",
    "g['total_charge_hit_terms'] = np.empty(x.shape)\n",
    "g['total_charge_terms'] = np.empty(x.shape)\n",
    "\n",
    "for idx in np.ndindex(x.shape):\n",
    "    hypo_x =  x[idx]\n",
    "    hypo_b =  y[idx]\n",
    "    hypo_t = 0\n",
    "    hypo_N_src = example_N_src\n",
    "    g['dom_hit_term'][idx] = -toy_experiment.dom_hit_term(test_event[1], hypo_x, hypo_b, 0)\n",
    "    g['dom_charge_terms'][idx] = -toy_experiment.dom_charge_term(test_event[0], hypo_x, hypo_b, hypo_N_src)\n",
    "    g['total_charge_hit_terms'][idx] = -toy_experiment.total_charge_hit_term(test_event[1], hypo_x, hypo_b, hypo_t, hypo_N_src)\n",
    "    g['total_charge_terms'][idx] = -toy_experiment.total_charge_term(test_event[0], hypo_x, hypo_b, hypo_N_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['total_charge_llh'] = g['total_charge_hit_terms'] + g['total_charge_terms']\n",
    "g['dom_llh'] -= np.min(g['dom_llh'])\n",
    "g['total_charge_llh'] -= np.min(g['total_charge_llh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, txt=0, **kwargs):\n",
    "    m=axes[0].pcolormesh(x, y, a, cmap='Spectral', vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "    plt.colorbar(m, ax=axes[0])\n",
    "    axes[0].set_title(title_a)\n",
    "    m=axes[1].pcolormesh(x, y, b, cmap='Spectral', vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "    plt.colorbar(m, ax=axes[1])\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    vlim = min(np.max(np.abs(diff)), vmax)\n",
    "    m=axes[2].pcolormesh(x, y, diff, cmap='RdBu', vmin=-vlim, vmax=vlim, label=r'$\\Delta LLH$', **kwargs)\n",
    "    plt.colorbar(m, ax=axes[2])\n",
    "    axes[2].set_title('diff')\n",
    "    if txt == 1:\n",
    "        p = np.unravel_index(np.argmax(np.abs(diff), axis=None), a.shape)\n",
    "        axes[2].text(-3.5, 1.5, r'Max abs diff = %.1f (%.2f)'%(np.max(np.abs(diff)), (a[p]-b[p])/a[p]), size=15)\n",
    "        #plt.scatter(x[p], y[p], color='red', marker='x')\n",
    "    elif txt > 1:\n",
    "        vs = np.abs(diff[np.abs(diff) <= txt])\n",
    "        axes[2].text(-3, 1.5, r'Mean diff = %.1f'%(np.sum(vs)/len(vs)), size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_truth(axes, x, y):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([x], [y], marker='$T$', markersize=10, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "plot_diff(g['dom_hit_term'], g['total_charge_hit_terms'], axes=ax[0], title_a='per DOM hit', title_b='total hit', vmax=200)\n",
    "plot_diff(g['dom_charge_terms'], g['total_charge_terms'], axes=ax[1], title_a='per DOM charge', title_b='total charge', vmax=200)\n",
    "plot_diff(g['dom_llh'], g['total_charge_llh'], axes=ax[2], title_a='per DOM llh', title_b='total llh', vmax=200)\n",
    "\n",
    "plot_truth(ax, example_x_src, example_b_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm events.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "fname = 'events.pkl'\n",
    "if os.path.isfile(fname):\n",
    "    with open(fname, 'rb') as file:\n",
    "        events = pickle.load(file)\n",
    "    \n",
    "    #with open('events_close.pkl', 'rb') as file:\n",
    "    #    events2 = pickle.load(file) \n",
    "    \n",
    "else:\n",
    "    # generate some MC (it's very slow right now....about 15min for 1e5, but I don't mind)\n",
    "    events = toy_experiment.generate_events(int(1e5), N_lims=(0, 20))\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump(events, file, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "    \n",
    "    #events2 = toy_experiment.generate_events(int(1e5), N_lims=(0, 20), blims=(-0.5,0.5))\n",
    "    #with open('events_close.pkl', 'wb') as file:\n",
    "    #    pickle.dump(events2, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc, truth = events\n",
    "#mc2, truth2 = events2\n",
    "#mc = np.append(mc, mc2, axis=0)\n",
    "#truth = np.append(truth, truth2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitnet = SimpleNamespace()\n",
    "chargenet = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data generator and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x, t, batch_size=4096, shuffle='event', weights=False):\n",
    "        \n",
    "        self.batch_size = int(batch_size/2) # half true labels half false labels\n",
    "        self.data = x\n",
    "        self.params = t\n",
    "        if shuffle == 'event':\n",
    "            self.shuffled_params = np.roll(t, len(toy_experiment.detector_xs), axis=0)\n",
    "        elif shuffle == 'DOM':\n",
    "            self.shuffled_params = np.empty_like(self.params)\n",
    "            for DOM_index in range(11):\n",
    "                mask = self.data[:, 2] == DOM_index\n",
    "                self.shuffled_params[mask] = np.random.permutation(self.params[mask])\n",
    "        \n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        self.shuffle = shuffle\n",
    "        self.weights = weights\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y, w = self.__data_generation(indexes) #\n",
    "\n",
    "        return X, y, w\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        np.random.shuffle(self.indexes) # mix between batches\n",
    "        if self.shuffle == 'event':\n",
    "            self.shuffled_params = np.roll(self.shuffled_params, len(toy_experiment.detector_xs), axis=0)\n",
    "\n",
    "    def __data_generation(self, indexes_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Generate data similar to Data.get_dataset()\n",
    "        x = np.take(self.data, indexes_temp, axis=0)\n",
    "        t = np.take(self.params, indexes_temp, axis=0)\n",
    "        if self.shuffle == 'event' or self.shuffle == 'DOM':\n",
    "            t_shuffle = np.take(self.shuffled_params, indexes_temp, axis=0)\n",
    "\n",
    "        d_true_labels = np.ones((self.batch_size, 1), dtype=x.dtype)\n",
    "        d_false_labels = np.zeros((self.batch_size, 1), dtype=x.dtype)\n",
    "        \n",
    "        d_X = np.append(x, x, axis=0)\n",
    "        if self.shuffle == 'event' or self.shuffle == 'DOM':\n",
    "            d_T = np.append(t, t_shuffle, axis=0)\n",
    "        else:\n",
    "            d_T = np.append(t, np.random.permutation(t), axis=0)\n",
    "        d_labels = np.append(d_true_labels, d_false_labels)\n",
    "        \n",
    "        d_X, d_T, d_labels = self.unison_shuffled_copies(d_X, d_T, d_labels)\n",
    "        \n",
    "        #weights = np.where((d_X[:,0]+1) * (np.sqrt(np.square(d_T[:,0]-d_X[:,1])+np.square(d_T[:,1]))+0.05) < 0.5, 1000, 1)\n",
    "        #R = np.sqrt(np.square(d_T[:,0]-d_X[:,1])+np.square(d_T[:,1]))\n",
    "        if self.weights:\n",
    "            weights = d_T[:,2] #np.clip(d_T[:,2], 0, 2) #d_X[:,0]/100+1\n",
    "        else:\n",
    "            weights = np.ones(len(d_T[:,2]))\n",
    "\n",
    "        return [d_X, d_T], d_labels, weights\n",
    "    \n",
    "    def unison_shuffled_copies(self, a, b, c):\n",
    "        'Shuffles arrays in the same way'\n",
    "        assert len(a) == len(b) == len(c)\n",
    "        p = np.random.permutation(len(a))\n",
    "        \n",
    "        return a[p], b[p], c[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2(x):\n",
    "    return tf.where(x >= 0, x+tf.math.pow(x, 2), 0) #*tf.math.exp(x/30) , 0.1*x\n",
    "    \n",
    "class combi_activation(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(combi_activation, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.a = self.add_weight(\n",
    "            shape=(1, input_shape[-1]),\n",
    "            initializer=tf.keras.initializers.RandomUniform(0, 1),\n",
    "            trainable=True,\n",
    "            name='a',\n",
    "            constraint=lambda x: tf.clip_by_value(x, 0, 3)\n",
    "        )\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape=(1, input_shape[-1]),\n",
    "            initializer='ones',\n",
    "            trainable=True,\n",
    "            name='b',\n",
    "            constraint=lambda x: tf.clip_by_value(x, 0, 3)\n",
    "        )\n",
    "\n",
    "        self.c = self.add_weight(\n",
    "            shape=(1,), #input_shape[-1]\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='c',\n",
    "            constraint=lambda x: tf.clip_by_value(x, 0, 0.2)\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        pos = self.a*inputs + self.b*tf.math.pow(inputs, 2) \n",
    "        neg = self.c*inputs\n",
    "        return tf.where(inputs >= 0, pos, neg)\n",
    "\n",
    "\n",
    "class ParametricSoftExp(tf.keras.layers.Layer):\n",
    "    def __init__(self, init_alpha=0.0, init_stdv=0.01, **kwargs):\n",
    "        \"\"\"\n",
    "        Soft Exponential activation function with trainable alpha.\n",
    "        We initialize alpha from a random uniform distribution.\n",
    "        Layer can be used as an advanced layer that learns/changes during the optimization process.\n",
    "        See: https://arxiv.org/pdf/1602.01321.pdf by Godfrey and Gashler\n",
    "        Soft Exponential f(α, x):\n",
    "           α == 0:  x\n",
    "           α  > 0:  (exp(αx)-1) / α + α\n",
    "           α  < 0:  -ln(1-α(x + α)) / α\n",
    "        :param init_alpha:\n",
    "        :param init_stdv:\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        super(ParametricSoftExp, self).__init__(**kwargs)\n",
    "        self.init_mean = init_alpha\n",
    "        self.init_stdv = init_stdv\n",
    "        self.atol = tf.constant(1e-08)\n",
    "        \n",
    "    def build(self, temp):\n",
    "        # Initialize alpha\n",
    "        alpha_init = tf.random_normal_initializer(mean=self.init_mean, stddev=self.init_stdv)\n",
    "        self.alpha_actv = tf.Variable(initial_value=alpha_init(shape=(1,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call_lt0(self, x):\n",
    "        return -(tf.math.log(1 - self.alpha_actv * (x + self.alpha_actv))) / (self.alpha_actv)\n",
    "    def call_gt0(self, x):\n",
    "        return (tf.math.exp(self.alpha_actv * x) - 1) / self.alpha_actv + self.alpha_actv\n",
    "    def call(self, x):\n",
    "        x = 4*(x-tf.reduce_min(x))/(tf.reduce_max(x)-tf.reduce_min(x)) - 2 #tf.clip_by_value(x, -5, 5)\n",
    "        # Check for equal-ness first, based on a certain tolerance.\n",
    "        cond_equal = tf.less_equal(tf.abs(self.alpha_actv), self.atol)\n",
    "        # Otherwise go to greater or lower than zero\n",
    "        res = K.switch(cond_equal, x, K.switch(self.alpha_actv > 0, self.call_gt0(x), self.call_lt0(x)))\n",
    "        #res = tf.clip_by_value(res, -1000, 1000)\n",
    "        return res\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'alpha_init': float(self.init_mean)}\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_charge_infos(doms, truth):\n",
    "    c = np.sum(doms[:,0])\n",
    "    n = np.count_nonzero(doms[:,0])\n",
    "    #if n == 0:\n",
    "    #    r2c = 10\n",
    "    #else:\n",
    "    #    r2c = np.min(np.square(truth[0] - doms[:,1][doms[:,0]!=0]) + np.square(truth[1]))\n",
    "    #if n == 11:\n",
    "    #    r2n = 10\n",
    "    #else:\n",
    "    #    r2n = np.min(np.square(truth[0] - doms[:,1][doms[:,0]==0]) + np.square(truth[1]))\n",
    "    return [c, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typ = 'dom'  #'total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargenet.x = []\n",
    "hitnet.x = []\n",
    "n_hits_per_event = []\n",
    "failures = []\n",
    "for i, item in enumerate(mc):\n",
    "    if np.sum(item[0][:,0]) == 0:\n",
    "        failures.append(i)\n",
    "        continue\n",
    "    chargenet.x.append(item[0]) #get_total_charge_infos(item[0], truth[i])\n",
    "    hitnet.x.append(item[1])\n",
    "    n_hits_per_event.append(item[1].shape[0])\n",
    "truth = np.delete(truth, failures, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargenet.x = np.concatenate(chargenet.x) #np.array(chargenet.x)\n",
    "hitnet.x = np.concatenate(hitnet.x)\n",
    "n_hits_per_event = np.array(n_hits_per_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargenet.t = np.repeat(truth, len(toy_experiment.detector_xs), axis=0) #truth\n",
    "hitnet.t = np.repeat(truth, n_hits_per_event, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert chargenet.x.shape[0] == chargenet.t.shape[0]\n",
    "assert hitnet.x.shape == hitnet.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## charge Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargenet.x_train, chargenet.x_test, chargenet.t_train, chargenet.t_test = train_test_split(chargenet.x, chargenet.t, test_size=0.2, random_state=42)\n",
    "\n",
    "# some nasty gymnastics to get the NN inputs for the grid scan\n",
    "chargenet.tt = np.vstack([x.flatten(), y.flatten(), np.ones(np.prod(x.shape)) * example_N_src]).T\n",
    "if Typ == 'dom':\n",
    "    chargenet.tts = np.repeat(chargenet.tt, len(toy_experiment.detector_xs), axis=0)\n",
    "    \n",
    "    chargenet.xxs = np.repeat(test_event[0][np.newaxis,:, :], np.prod(x.shape), axis=0)\n",
    "    chargenet.xxs = chargenet.xxs.reshape(-1, 3)\n",
    "    \n",
    "elif Typ == 'total':\n",
    "    chargenet.tts = chargenet.tt\n",
    "    \n",
    "    chargenet.xxs = np.repeat(get_total_charge_infos(test_event[0], [example_x_src, example_b_src]), np.prod(x.shape), axis=0)\n",
    "    chargenet.xxs = chargenet.xxs.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = np.log(np.sqrt((chargenet.t[:,0]-chargenet.x[:,1])**2 + chargenet.t[:,1]**2))\n",
    "#np.mean(r), np.std(r)\n",
    "np.min(chargenet.t[:,2]), np.max(chargenet.t[:,2])-np.min(chargenet.t[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Typ == 'dom':\n",
    "    class charge_trafo(tf.keras.layers.Layer):\n",
    "\n",
    "        def call(self, charges, theta):\n",
    "            r2 = tf.math.square(theta[:,0] - charges[:,1]) + tf.math.square(theta[:,1])\n",
    "            r = tf.math.log(r2) #tf.math.sqrt()\n",
    "            #d = (charges[:,0])/(r2) #+0.05**2\n",
    "            #(charges[:,2]-5.0)/3.16,\n",
    "            out = tf.stack([\n",
    "                    #charges[:,0],\n",
    "                    (charges[:,0]-5.8)/62.1, \n",
    "                    #charges[:,1],\n",
    "                    (charges[:,1])/3.16,     \n",
    "                    #r2,\n",
    "                    (r-2.22)/1.46,           \n",
    "                    #theta[:,0],\n",
    "                    (theta[:,0])/2.89,       \n",
    "                    #theta[:,1],\n",
    "                    (theta[:,1])/1.15,       \n",
    "                    #theta[:,2]\n",
    "                    (theta[:,2]-9.98)/5.78\n",
    "                    ],\n",
    "                    axis=1\n",
    "                    ) \n",
    "            return out\n",
    "\n",
    "elif Typ == 'total':\n",
    "    class charge_trafo(tf.keras.layers.Layer):\n",
    "\n",
    "        def call(self, charges, theta):\n",
    "            out = tf.stack([\n",
    "                     charges[:,0],\n",
    "                     #(charges[:,0]-63.9)/205.7,\n",
    "                     #charges[:,1],\n",
    "                     #(charges[:,1]-6.)/2.36,\n",
    "                     theta[:,0],\n",
    "                     #(theta[:,0])/2.89,\n",
    "                     theta[:,1],\n",
    "                     #(theta[:,1])/1.15,\n",
    "                     theta[:,2]\n",
    "                     #(theta[:,2]-9.98)/5.78\n",
    "                    ],\n",
    "                    axis=1\n",
    "                    ) \n",
    "            return out\n",
    "\n",
    "chargenet.trafo = charge_trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charge_model(activation='relu'):\n",
    "    x_input = tf.keras.Input(shape=(chargenet.x.shape[1],)) #_train\n",
    "    t_input = tf.keras.Input(shape=(chargenet.t.shape[1],)) #_train\n",
    "\n",
    "    inp = chargenet.trafo()(x_input, t_input)\n",
    "\n",
    "    h = tf.keras.layers.Dense(32, activation=activation)(inp)\n",
    "    #h = tf.keras.layers.Activation(x2)(h)\n",
    "    #h = combi_activation()(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(64, activation=activation)(h)\n",
    "    #h = combi_activation()(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(128, activation=None)(h)\n",
    "    #h = tf.keras.layers.Activation(x2)(h)\n",
    "    h = combi_activation()(h)\n",
    "    #h = mini_layer(h, 128)\n",
    "    #h = residual_layer(h, 128, activation)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(64, activation=activation)(h)\n",
    "    #h = combi_activation()(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(32, activation=None)(h)\n",
    "    #h = tf.keras.layers.Activation(x2)(h)\n",
    "    h = combi_activation()(h)\n",
    "    #h = mini_layer(h, 32)\n",
    "    #h = residual_layer(h, 32, activation)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "    \n",
    "    #h = tf.keras.layers.Dense(16, activation=activation)(h)\n",
    "    #h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[x_input, t_input], outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = get_charge_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync\n",
    "\n",
    "with strategy.scope():\n",
    "    cmodel = get_charge_model(activation=tfa.activations.mish) #\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    #radam = tfa.optimizers.RectifiedAdam(lr=1e-3)\n",
    "    #optimizer = tfa.optimizers.Lookahead(radam)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    cmodel.compile(loss=bce, optimizer=optimizer, metrics=['accuracy']) #, run_eagerly=True\n",
    "\n",
    "#chargenet.d_train = get_dataset(chargenet.x_train, chargenet.t_train)\n",
    "#chargenet.d_test = get_dataset(chargenet.x_test, chargenet.t_test, test=True)\n",
    "d_train = DataGenerator(chargenet.x[int(0.2*len(chargenet.x)):], chargenet.t[int(0.2*len(chargenet.x)):], batch_size=4096*nGPUs, weights=True)\n",
    "d_test = DataGenerator(chargenet.x[:int(0.2*len(chargenet.x))], chargenet.t[:int(0.2*len(chargenet.x))], batch_size=4096*nGPUs, weights=True)\n",
    "\n",
    "hist = cmodel.fit(d_train, epochs=15, verbose=1, validation_data=d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cmodel.history.history['loss'])\n",
    "plt.plot(cmodel.history.history['val_loss'])\n",
    "plt.gca().set_yscale('log')\n",
    "#plt.ylim(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargenet.llh = cmodel\n",
    "chargenet.llh.layers[-1].activation = tf.keras.activations.linear\n",
    "chargenet.llh.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargenet.llhs = chargenet.llh.predict([chargenet.xxs, chargenet.tts])\n",
    "\n",
    "if Typ == 'dom':\n",
    "    g['charge_llh'] = -np.sum(chargenet.llhs.reshape(-1, len(toy_experiment.detector_xs)), axis=1).reshape(x.shape)\n",
    "elif Typ == 'total':\n",
    "    g['charge_llh'] = -chargenet.llhs.reshape(x.shape)\n",
    "g['charge_llh'] -= np.min(g['charge_llh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\n",
    "typ = Typ+'_charge_terms'\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['charge_llh'], title_a='Analytic', title_b='NN', vmax=20, axes=ax[0]) #, txt=20\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['charge_llh'], title_a='Analytic', title_b='NN', vmax=2, axes=ax[1]) #, txt=2\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['charge_llh'], title_a='Analytic', title_b='NN', vmax=200, axes=ax[2], txt=1)\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "\n",
    "#plt.savefig('../../plots/toy_model/xy_old_close', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,17))\n",
    "ax3D = fig.add_subplot(111, projection='3d')\n",
    "LLH = g[typ]-np.min(g[typ])\n",
    "\n",
    "ax3D.plot_surface(X=x, Y=y, Z=g['charge_llh']) #, cmap='RdBu'\n",
    "#ax3D.plot_surface(X=x, Y=y, Z=LLH)\n",
    "#ax3D.plot_surface(X=x, Y=y, Z=LLH-g['charge_llh'], cmap='RdBu', vmin=-2, vmax=2)\n",
    "#ax3D.plot_surface(X=x, Y=y, Z= np.divide(LLH-g['charge_llh'], LLH, out=np.zeros_like(LLH), where=LLH>0.1), cmap='RdBu', vmin=-1, vmax=1)\n",
    "ax3D.set_zlim(0, 820)\n",
    "#ax3D.set_xlim(-1, 1)\n",
    "#ax3D.set_ylim(-1, 1)\n",
    "\n",
    "#plt.savefig('../../plots/toy_model/xy_old_3D_close', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = np.vstack([np.ones(100)*example_x_src, np.ones(100)*example_b_src, np.linspace(0.01, 10, 100)]).T\n",
    "if Typ == 'dom':\n",
    "    tts = np.repeat(tt, len(toy_experiment.detector_xs), axis=0)\n",
    "    \n",
    "    xxs = np.repeat(test_event[0][np.newaxis,:, :], 100, axis=0)\n",
    "    xxs = xxs.reshape(-1, 3)\n",
    "\n",
    "llhs = chargenet.llh.predict([xxs, tts])\n",
    "\n",
    "if Typ == 'dom':\n",
    "    C = -np.sum(llhs.reshape(-1, len(toy_experiment.detector_xs)), axis=1)\n",
    "C -= np.min(C)\n",
    "\n",
    "T = []\n",
    "for i in np.linspace(0.01, 10, 100):\n",
    "    T.append(-toy_experiment.dom_charge_term(test_event[0], example_x_src, example_b_src, i))\n",
    "T -= np.min(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0.01, 10, 100), C)\n",
    "#plt.plot(np.linspace(0.01, 10, 100), T)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOM hit Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hitnet.x_train, hitnet.x_test, hitnet.t_train, hitnet.t_test = train_test_split(hitnet.x, hitnet.t, test_size=0.2, random_state=42)\n",
    "\n",
    "# some nasty gymnastics to get the NN inputs for the grid scan\n",
    "hitnet.tt = np.vstack([x.flatten(), y.flatten(), np.ones(np.prod(x.shape)) * example_N_src]).T\n",
    "hitnet.tts = np.repeat(hitnet.tt, test_event[1].shape[0], axis=0)\n",
    "\n",
    "hitnet.xxs = np.repeat(test_event[1][np.newaxis,:, :], np.prod(x.shape), axis=0)\n",
    "hitnet.xxs = hitnet.xxs.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(np.sqrt((hitnet.t[:,0]-hitnet.x[:,1])**2 + hitnet.t[:,1]**2))\n",
    "np.mean(r), np.std(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hit_trafo(tf.keras.layers.Layer):\n",
    "\n",
    "    def call(self, hits, theta):\n",
    "        c = 0.3\n",
    "        r2 = tf.math.square(theta[:,0] - hits[:,1]) + tf.math.square(theta[:,1])\n",
    "        r = tf.math.sqrt(r2)\n",
    "        \n",
    "        delta_t = hits[:,0] - r/c \n",
    "        \n",
    "        out = tf.stack([\n",
    "                 (hits[:,0]-2.6)/3.64,\n",
    "                 (hits[:,1])/2.93,\n",
    "                 (r-0.77)/1.05,\n",
    "                 delta_t,\n",
    "                 (theta[:,0])/2.87,\n",
    "                 (theta[:,1])/0.622,\n",
    "                 (theta[:,2]-13.3)/4.69\n",
    "                ],\n",
    "                axis=1\n",
    "                )    \n",
    "        return out\n",
    "hitnet.trafo = hit_trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_model(activation='relu'):\n",
    "    x_input = tf.keras.Input(shape=(hitnet.x.shape[1],))\n",
    "    t_input = tf.keras.Input(shape=(hitnet.t.shape[1],))\n",
    "\n",
    "    h = hitnet.trafo()(x_input, t_input)\n",
    "\n",
    "    h = tf.keras.layers.Dense(32, activation=activation)(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(64, activation=activation)(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(128, activation=activation)(h)\n",
    "    #h = tf.keras.layers.Activation(x2)(h)\n",
    "    #h = combi_activation()(h)\n",
    "    #h = ParametricSoftExp()(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(64, activation=activation)(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    h = tf.keras.layers.Dense(32, activation=activation)(h)\n",
    "    h = tf.keras.layers.Dropout(0.01)(h)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[x_input, t_input], outputs=outputs)\n",
    "    #hitnet.model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = get_hit_model(activation=tfa.activations.mish)\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    #radam = tfa.optimizers.RectifiedAdam(lr=0.001)\n",
    "    #optimizer = tfa.optimizers.Lookahead(radam)\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "#chargenet.d_train = get_dataset(chargenet.x_train, chargenet.t_train)\n",
    "#chargenet.d_test = get_dataset(chargenet.x_test, chargenet.t_test, test=True)\n",
    "d_train = DataGenerator(hitnet.x[:int(0.8*len(hitnet.x))], hitnet.t[:int(0.8*len(hitnet.x))], batch_size=4096*nGPUs, shuffle='free')\n",
    "d_test = DataGenerator(hitnet.x[int(0.8*len(hitnet.x)):], hitnet.t[int(0.8*len(hitnet.x)):], batch_size=4096*nGPUs, shuffle='free')\n",
    "\n",
    "hist = hmodel.fit(d_train, epochs=4, verbose=1, validation_data=d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hmodel.history.history['loss'])\n",
    "plt.plot(hmodel.history.history['val_loss'])\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitnet.llh = hmodel\n",
    "hitnet.llh.layers[-1].activation = tf.keras.activations.linear\n",
    "hitnet.llh.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitnet.llhs = hitnet.llh.predict([hitnet.xxs, hitnet.tts])\n",
    "\n",
    "g['hit_llh'] = -np.sum(hitnet.llhs.reshape(-1, test_event[1].shape[0]), axis=1).reshape(x.shape)\n",
    "g['hit_llh'] -= np.min(g['hit_llh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typ = 'total_charge_hit_terms' #'dom_hit_term'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\n",
    "typ = Typ\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['hit_llh'], title_a='Analytic', title_b='NN', vmax=20, axes=ax[0]) #, txt=20\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['hit_llh'], title_a='Analytic', title_b='NN', vmax=2, axes=ax[1]) #, txt=2\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g[typ]-np.min(g[typ]), g['hit_llh'], title_a='Analytic', title_b='NN', vmax=200, axes=ax[2], txt=1)\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "\n",
    "#plt.savefig('../../plots/toy_model/xy_old_hit', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,17))\n",
    "ax3D = fig.add_subplot(111, projection='3d')\n",
    "LLH = g['dom_hit_term']-np.min(g['dom_hit_term'])\n",
    "\n",
    "ax3D.plot_surface(X=x, Y=y, Z=g['hit_llh'], cmap='RdBu')\n",
    "#ax3D.plot_surface(X=x, Y=y, Z=LLH)\n",
    "#ax3D.plot_surface(X=x, Y=y, Z=LLH-g['hit_llh'], cmap='RdBu', vmin=-2, vmax=2)\n",
    "#ax3D.plot_surface(X=x, Y=y, Z= np.divide(LLH-g['hit_llh'], LLH, out=np.zeros_like(LLH), where=LLH!=0), cmap='RdBu', vmin=-1, vmax=1)\n",
    "ax3D.set_zlim(0, np.max(LLH))\n",
    "#plt.savefig('../../plots/toy_model/hit_LLH_NN_3D_zoomOut', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = 8\n",
    "print(hmodel.weights[l].name)\n",
    "plt.hist(hmodel.weights[l].values[0].numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['llh'] = g['charge_llh'] + g['hit_llh']\n",
    "g['llh'] -= np.min(g['llh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\n",
    "plot_diff(g['dom_hit_term']-np.min(g['dom_hit_term']), g['hit_llh'], title_a='Hit Analytic', title_b='Hit NN', vmax=20, axes=ax[0], txt=1)\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g['dom_charge_terms']-np.min(g['dom_charge_terms']), g['charge_llh'], title_a='Charge Analytic', title_b='Charge NN', vmax=20, axes=ax[1], txt=1)\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "plot_diff(g['dom_llh']-np.min(g['dom_llh']), g['llh'], title_a='Analytic', title_b='NN', vmax=20, axes=ax[2], txt=1)\n",
    "plot_truth(ax, example_x_src, example_b_src)\n",
    "\n",
    "#plt.savefig('../../plots/toy_model/event3', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
