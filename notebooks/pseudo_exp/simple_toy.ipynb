{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import curve_fit\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dama as dm\n",
    "import pickle\n",
    "import awkward as ak\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from freedom.toy_model.toy_model_functions import toy_model\n",
    "from freedom.toy_model.detectors import get_box_detector\n",
    "from types import SimpleNamespace\n",
    "#from toy_NN_trafo import build_q_trafo, build_h_trafo\n",
    "from freedom.toy_model import NNs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "\n",
    "par_names = ['x', 'y', 'z', 't', 'azi', 'zen', 'E', 'I']\n",
    "\n",
    "def plot_truth(axes, truth, idx=(0,1)):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([truth[idx[0]]], [truth[idx[1]]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, limit_diff=False, **kwargs):\n",
    "    \n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    #a.plot(ax=axes[0], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    a.plot_contour(ax=axes[0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta$LLH', **kwargs)\n",
    "    axes[0].set_title(title_a)\n",
    "    #b.plot(ax=axes[1], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    b.plot_contour(ax=axes[1], levels=levels,  labels=labels, colors=colors, label=r'$\\Delta$LLH', **kwargs)\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    if limit_diff:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-vmax, vmax=vmax, label=r'$\\Delta$LLH', **kwargs)\n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #np.clip(-diff, 0, None).plot_contour(ax=axes[2], levels=[0.1,0.2, 0.3], colors=['r']*2)\n",
    "    else:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)), label=r'$\\Delta$LLH', **kwargs) \n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[2].set_title('Difference') #axes[2].set_title(title_a + ' - ' + title_b)\n",
    "    \n",
    "def plot_point_dense(x, y):\n",
    "    xy = np.vstack([x,y])\n",
    "    z = stats.gaussian_kde(xy)(xy)\n",
    "    \n",
    "    idx = z.argsort()\n",
    "\n",
    "    plt.scatter(x[idx], y[idx], c=z[idx])\n",
    "    #plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = get_box_detector(x=np.linspace(-5,5,5), y=[0,], z=[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([1., 1., 0, 0, 0, np.arccos(1), 2., 0.5]) #x, y, z, t, az, zen, energy, inelast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(truth)\n",
    "test_event[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid scan\n",
    "\n",
    "g = dm.GridData(x=np.linspace(-7, 7, 100), y=np.linspace(-2, 2, 100))\n",
    "#g = dm.GridData(x=np.linspace(1, 7, 100), y=np.linspace(0, 1, 100))\n",
    "IDX = (0,1)\n",
    "\n",
    "g['dom_hit_term'] = np.empty(g.shape)\n",
    "g['dom_charge_terms'] = np.empty(g.shape)\n",
    "g['total_charge_hit_terms'] = np.empty(g.shape)\n",
    "g['total_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g.shape):\n",
    "    p[IDX[0]] =  g['x'][idx]\n",
    "    p[IDX[1]] =  g['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    g['total_charge_hit_terms'][idx] = toy_experiment.nllh_p_term_tot(segments, test_event[0])\n",
    "    g['total_charge_terms'][idx] = toy_experiment.nllh_N_term_tot(segments, test_event[1])\n",
    "    \n",
    "g['dom_hit_term'] -= g['dom_hit_term'].min()\n",
    "g['dom_charge_terms'] -= g['dom_charge_terms'].min()\n",
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['total_charge_hit_terms'] -= g['total_charge_hit_terms'].min()\n",
    "g['total_charge_terms'] -= g['total_charge_terms'].min()\n",
    "g['total_charge_llh'] = g['total_charge_hit_terms'] + g['total_charge_terms']\n",
    "g['dom_llh'] -= g['dom_llh'].min()\n",
    "g['total_charge_llh'] -= g['total_charge_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(12,12))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.25)\n",
    "\n",
    "plot_diff(g['dom_hit_term'], g['total_charge_hit_terms'], axes=ax[0], title_a=r'Per-sensor $p_{s}(x_{i,s}|\\theta)$ terms', title_b=r'All-sensor $p_{s_{i}}^{tot}(x_{i}|\\theta)$ terms', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_charge_terms'], g['total_charge_terms'], axes=ax[1], title_a=r'Per-sensor $P_{s}(N_{s}|\\theta)$ terms', title_b=r'All-sensor $P_{tot}(N_{tot}|\\theta)$ term', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_llh'], g['total_charge_llh'], axes=ax[2], title_a='Per-sensor LLH', title_b='All-sensor LLH', limit_diff=False)\n",
    "\n",
    "plot_truth(ax, truth, IDX)\n",
    "for i, a in enumerate(ax.flatten()): \n",
    "    if i in [6,7,8]: \n",
    "        a.set_xlabel('x')\n",
    "    else:\n",
    "        a.set_xlabel('')\n",
    "    if i in [0,3,6]: \n",
    "        a.set_ylabel('y')\n",
    "    else:\n",
    "        a.set_ylabel('')\n",
    "\n",
    "#plt.savefig('../../plots/thesis/eml_decomp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE, Set = 2_560_000, 0\n",
    "events, meta = toy_experiment.generate_events(n=NE, gamma=0, gen_volume=\"box\", e_lim=(1,7), inelast_lim=(0,1),\n",
    "                                              x_lim=(-7,7), y_lim=(-2, 2), z_lim=(0,0), t_width=0, coszen_lim=(1,1),\n",
    "                                              contained=False, min_hits=3, rand=Set)\n",
    "#truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.count(events.photons.t, axis=1).to_numpy(), np.linspace(0,100,101))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, time_spread=0) #10 30\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, time_spread=0) #10 30\n",
    "\n",
    "#size = sys.getsizeof(d_train.indexes) + sys.getsizeof(d_train.data) + sys.getsizeof(d_train.params)\n",
    "#size += sys.getsizeof(d_valid.indexes) + sys.getsizeof(d_valid.data) + sys.getsizeof(d_valid.params)\n",
    "#size * 10e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo, activation='swish', final_activation='swish',\n",
    "                            nodes=250, n_layer=12) # big:(300,14), small:(200,10)\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "#hmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel.fit(d_train, epochs=15, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_total = llhs.reshape(g.shape)\n",
    "g.hit_llh_total -= g.hit_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "#plt.suptitle(str(NE)+' events', size=17)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, g.hit_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "for a in ax:\n",
    "    a.set_xlabel(par_names[IDX[0]])\n",
    "    a.set_ylabel(par_names[IDX[1]])\n",
    "\n",
    "#plt.savefig('images/simple_tests/llh_scan_xt'+str(NE)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel.save('networks/simple_toy/'+str(NE)+'/simple_toy_hitnet_total_'+str(NE)+'_set'+str(Set)+'.h5')\n",
    "hmodel_t = tf.keras.models.load_model('networks/simple_toy/2560000/simple_toy_hitnet_total_2560000_set4.h5',\n",
    "                                       custom_objects={'hit_trafo':NNs.hit_trafo})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_charge_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "with strategy.scope():\n",
    "    cmodel = NNs.get_cmodel(x_shape=2, t_shape=8, trafo=NNs.charge_trafo, activation='swish', final_activation='swish',\n",
    "                            nodes=300, n_layer=15) # big:(170,13), small:(130,9)\n",
    "    cmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "#cmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = cmodel.fit(d_train, epochs=30, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = cmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.tile([len(test_event[0]), len(np.unique(test_event[0][:,0]))], np.prod(g.shape))\n",
    "xxs = xxs.reshape(-1, 2)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "\n",
    "cmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "cmodel.compile()\n",
    "\n",
    "llhs = np.nan_to_num(-cmodel.predict((xxs, tts), batch_size=4096))\n",
    "\n",
    "g.charge_llh_total = llhs.reshape(g.shape)\n",
    "g.charge_llh_total -= g.charge_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.total_charge_terms, g.charge_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/chargeNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmodel.save('networks/simple_toy/'+str(NE)+'/simple_toy_chargenet_total_'+str(NE)+'_set'+str(Set)+'.h5')\n",
    "cmodel_t = tf.keras.models.load_model('networks/simple_toy/2560000/simple_toy_chargenet_total_2560000_set4.h5',\n",
    "                                      custom_objects={'charge_trafo':NNs.charge_trafo})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, \n",
    "          g.hit_llh_total, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "\n",
    "plot_diff(g.total_charge_terms, \n",
    "          g.charge_llh_total, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "\n",
    "ana, NN = g.total_charge_hit_terms+g.total_charge_terms, g.hit_llh_total+g.charge_llh_total\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "#plt.savefig('images/NNtest_totalC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - per dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=30)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo, activation='swish', final_activation='swish')\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel.fit(d_train, epochs=7, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_dom = llhs.reshape(g.shape)\n",
    "g.hit_llh_dom -= g.hit_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_hit_term, g.hit_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel.save('networks/simple_toy/simple_toy_hitnet_dom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_dom_data(events, detector)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    dmodel = NNs.get_hmodel(x_shape=4, t_shape=8, trafo=NNs.dom_trafo, activation='swish', final_activation='swish')\n",
    "    dmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dmodel.fit(d_train, epochs=60, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = dmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "dmodel.compile()\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g.charge_llh_dom = llhs.reshape(g.shape)\n",
    "g.charge_llh_dom -= g.charge_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, g.charge_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmodel.save('networks/simple_toy/simple_toy_chargenet_dom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.dom_hit_term, \n",
    "          g.hit_llh_dom, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, \n",
    "          g.charge_llh_dom, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "\n",
    "ana, NN = g.dom_hit_term+g.dom_charge_terms, g.hit_llh_dom+g.charge_llh_dom\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "#plt.savefig('images/NNtest_perDOM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay(a, b, ax, **kwargs):\n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    a.plot_contour(ax=ax, levels=levels, labels=labels, colors=colors, **kwargs)\n",
    "    b.plot_contour(ax=ax, levels=levels, linestyles=[':']*len(levels), colors=colors, **kwargs)\n",
    "    ax.plot([], [], label='Analytic', color='Tab:blue')\n",
    "    ax.plot([], [], label='NN', linestyle=':', color='Tab:blue')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['llh_dom'] = g['hit_llh_dom'] + g['charge_llh_dom']\n",
    "g['llh_total'] = g['hit_llh_total'] + g['charge_llh_total']\n",
    "g['llh_dom'] -= g['llh_dom'].min()\n",
    "g['llh_total'] -= g['llh_total'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(20,12))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "ax[0][0].set_title('HitNet', size=20)\n",
    "plot_overlay(g.dom_hit_term, g.hit_llh_dom, ax[0][0])\n",
    "ax[0][0].text(-7.3, 1, 'Per Sensor', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "ax[0][1].set_title('ChargeNet', size=20)\n",
    "plot_overlay(g.dom_charge_terms, g.charge_llh_dom, ax[0][1])\n",
    "\n",
    "ax[0][2].set_title('Complete LLH', size=20)\n",
    "plot_overlay(g.dom_llh, g.llh_dom, ax[0][2])\n",
    "ax[0][2].legend(loc='upper left')\n",
    "\n",
    "plot_overlay(g.total_charge_hit_terms, g.hit_llh_total, ax[1][0])\n",
    "ax[1][0].text(-7.3, 1, 'Total Detector', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "plot_overlay(g.total_charge_terms, g.charge_llh_total, ax[1][1])\n",
    "\n",
    "plot_overlay(g.total_charge_llh, g.llh_total, ax[1][2])\n",
    "\n",
    "#plt.savefig('images/NNtest_simple.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_data(truth, vec, bins):\n",
    "    t = truth.reshape((1,8))\n",
    "    ts = np.repeat(t, len(hits), axis=0)\n",
    "\n",
    "    r_t = np.exp(hmodel_t.predict([hits, ts], batch_size=5000)).flatten()\n",
    "    #r_d = np.exp(hmodel_d.predict([hits, ts], batch_size=5000)).flatten()\n",
    "\n",
    "    dists = distance.cdist(detector[:,:3], toy_experiment.model(*truth)[:,:3])\n",
    "    survive = toy_experiment.survival(dists)\n",
    "    hit_llh_p, hit_llh_ps = [], []\n",
    "    for b in bins:\n",
    "        mat = toy_experiment.pandel.pdf(b-dists*4.333, d=dists)\n",
    "        hit_llh_p.append(np.sum(np.sum(mat, axis=0) * vec))\n",
    "        hit_llh_ps.append(np.sum(np.sum(mat * survive, axis=0) * vec))\n",
    "    norm_p = np.sum(np.array(hit_llh_p)) * np.diff(bins)[0]\n",
    "    norm_ps = np.sum(np.array(hit_llh_ps)) * np.diff(bins)[0]\n",
    "    \n",
    "    return r_t, hit_llh_p, hit_llh_ps, norm_p, norm_ps #r_d,\n",
    "\n",
    "def get_charge_data(truth, exp_bins, exp_bins_fine):\n",
    "    t = truth.reshape((1,8))\n",
    "    ts_t = np.repeat(t, len(charges_t), axis=0)\n",
    "    #ts_d = np.repeat(t, len(charges_d), axis=0)\n",
    "\n",
    "    r_t = np.exp(cmodel.predict([charges_t, ts_t], batch_size=5000)).flatten()\n",
    "    #r_d = np.exp(dmodel.predict([charges_d, ts_d], batch_size=5000)).flatten()\n",
    "\n",
    "    N_exp = toy_experiment.N_exp(toy_experiment.model(*truth))\n",
    "    dom_c_llh = np.zeros(len(exp_bins))\n",
    "    for N in N_exp:\n",
    "        dom_c_llh += stats.poisson.pmf(exp_bins, mu=N)\n",
    "        \n",
    "    return r_t, N_exp, dom_c_llh #r_d,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, meta = toy_experiment.generate_events(n=10_000, gamma=0, gen_volume=\"box\", e_lim=(1,7), inelast_lim=(0,1),\n",
    "                                              x_lim=(-7,7), y_lim=(-2, 2), z_lim=(0,0), t_width=0, coszen_lim=(1,1),\n",
    "                                              contained=False, min_hits=3)\n",
    "truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hitnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hits = NNs.get_hit_data(events)[0]\n",
    "hits[:, 3] += np.random.normal(0, 10, len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-40,100,100)\n",
    "\n",
    "r_t, hit_llh_p, hit_llh_ps, norm_p, norm_ps = get_hit_data(np.array([3., 1., 0, 0, 0, np.arccos(1), 5., 0.8]), \n",
    "                                                           [4,0.2,0.2,0.2,0.2,0.2],\n",
    "                                                           bins)\n",
    "\n",
    "r_t2, hit_llh_p2, hit_llh_ps2, norm_p2, norm_ps2 = get_hit_data(\n",
    "                                                            np.array([-1., 1., 0, 0, 0, np.arccos(1), 1.5, 0.2]), \n",
    "                                                            [0.3,0.2,0.2,0.2,0.2,0.2,0.2],\n",
    "                                                            bins)\n",
    "\n",
    "r_t3, hit_llh_p3, hit_llh_ps3, norm_p3, norm_ps3 = get_hit_data(\n",
    "                                                            np.array([-5., 3., 0, 0, 0, np.arccos(1), 4., 0.9]), \n",
    "                                                            [3.6,0.2,0.2],\n",
    "                                                            bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7*0.618))\n",
    "\n",
    "#plt.hist(test_hits[:, 3], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x)$', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps)/norm_ps, c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t2, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps2)/norm_ps2, c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_t3, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps3)/norm_ps3, c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "plt.legend(prop={'size':14})\n",
    "#plt.title('All-sensor')\n",
    "plt.xlabel(r'$x$ = Hit time')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "#plt.savefig('images/simple_tests/NNtest_rweight_time', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chargenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "charges_t = NNs.get_charge_data(events)[0]\n",
    "#charges_d = NNs.get_dom_data(events, detector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_bins, exp_bins_fine = np.linspace(0,12,13), np.linspace(1,75,75)\n",
    "\n",
    "r_t, N_exp, dom_c_llh = get_charge_data(np.array([3., 1., 0, 0, 0, np.arccos(1), 5., 0.8]), exp_bins, exp_bins_fine)\n",
    "r_t2, N_exp2, dom_c_llh2 = get_charge_data(np.array([-1., 1., 0, 0, 0, np.arccos(1), 1.5, 0.2]), exp_bins, exp_bins_fine)\n",
    "r_t3, N_exp3, dom_c_llh3 = get_charge_data(np.array([-3., 3., 0, 0, 0, np.arccos(1), 4., 0.9]), exp_bins, exp_bins_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7*0.618))\n",
    "\n",
    "bins = np.linspace(1,75,75)\n",
    "#plt.hist(test_charges_t[:, 0], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(charges_t[:, 0], bins, label='p(x)', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp)), \n",
    "         c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t2, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp2)), \n",
    "         c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_t3, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp3)), \n",
    "         c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "#plt.title('All-sensor')\n",
    "plt.legend(prop={'size':14})\n",
    "plt.xlabel(r'$x$ = Charge (total detector)')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "#plt.savefig('images/simple_tests/NNtest_rweight_charge', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llh error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bounds = np.array([[-5,5], [-2,2], [0,0], [-50,50], [0,2*np.pi], [0,0], [0,5], [0,5]])\n",
    "uniforms = np.random.uniform(size=(50000, 8))\n",
    "Ps = bounds[:,0] + uniforms * (bounds[:,1] - bounds[:,0])\n",
    "\n",
    "\n",
    "llhs_ana = []\n",
    "for p in Ps:\n",
    "    segments = toy_experiment.model(*p)\n",
    "    llhs_ana.append(toy_experiment.nllh_p_term_tot(segments, test_event[0]))\n",
    "    \n",
    "llhs_ana = np.array(llhs_ana) - np.min(llhs_ana)\n",
    "'''\n",
    "\n",
    "xxs = np.repeat(test_event[0][np.newaxis, :], len(Ps), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "tts = np.repeat(Ps, len(test_event[0]), axis=0)\n",
    "\n",
    "llhs_nn = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs_nn = np.sum(np.nan_to_num(llhs_nn.reshape(-1, len(test_event[0]))), axis=1)\n",
    "llhs_nn -= np.min(llhs_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.suptitle(str(NE)+' events', size=17)\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_point_dense(llhs_nn-llhs_ana, llhs_ana)\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.xlabel(r'$\\Delta LLH_{NN} - \\Delta LLH_{true}$')\n",
    "plt.ylabel(r'$\\Delta LLH_{true}$')\n",
    "plt.text(np.min(llhs_nn-llhs_ana), 0, 'Mean(x) = %.2f'%(np.mean(llhs_nn-llhs_ana)), size=12)\n",
    "plt.text(np.min(llhs_nn-llhs_ana), 0.1*np.max(llhs_ana), 'STD(x) = %.2f'%(np.std(llhs_nn-llhs_ana)), size=12)\n",
    "plt.text(np.min(llhs_nn-llhs_ana), 0.2*np.max(llhs_ana), 'Median(|x|) = %.2f'%(np.median(np.abs(llhs_nn-llhs_ana))), size=12)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_point_dense((llhs_nn-llhs_ana)[llhs_ana<10], llhs_ana[llhs_ana<10])\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.xlabel(r'$\\Delta LLH_{NN} - \\Delta LLH_{true}$')\n",
    "plt.ylabel(r'$\\Delta LLH_{true}$')\n",
    "\n",
    "#plt.savefig('images/simple_tests/dLLH_error_'+str(NE)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_point_dense(Ps[:,3], llhs_nn-llhs_ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical_opt import spherical_opt\n",
    "from multiprocessing import Pool, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[-7,7], [-2,2], [-0.1,0.1], [-125,125], [0,2*np.pi], [-0.1,0.1], [1,7], [0,1]])\n",
    "\n",
    "def trafo(points, d=1):\n",
    "    if d == 1:\n",
    "        e = points[:,-2] + points[:,-1]\n",
    "        elas = points[:,-2]/e\n",
    "        points[:,-2] = e\n",
    "        points[:,-1] = elas\n",
    "    elif d == -1:\n",
    "        ecscd = points[:,-2] * points[:,-1]\n",
    "        etrck = points[:,-2] * (1-points[:,-1])\n",
    "        points[:,-2] = ecscd\n",
    "        points[:,-1] = etrck\n",
    "    else:\n",
    "        raise \n",
    "        \n",
    "    return points\n",
    "\n",
    "def init_points(hits, n_live_points, bound=bounds, seed=[None]):\n",
    "    if seed[0] == None:\n",
    "        avg = np.average(hits[:, :3], axis=0)\n",
    "        low_lims = np.concatenate([avg-np.array([3,2,0]), np.array([-30,0,0,1,0])])\n",
    "        hig_lims = np.concatenate([avg+np.array([3,2,0]), np.array([30,2*np.pi,0,7,1])])\n",
    "    else:\n",
    "        low_lims = seed - np.array([1, 0.5, 0, 5, 0.5, 0, 3, 0.3])\n",
    "        hig_lims = seed + np.array([1, 0.5, 0, 5, 0.5, 0, 3, 0.3])\n",
    "    \n",
    "    uniforms = np.random.uniform(size=(n_live_points, 8))\n",
    "    initial_points = low_lims + uniforms * (hig_lims - low_lims)\n",
    "    initial_points = np.clip(initial_points, bounds[:, 0], bounds[:, 1])\n",
    "    return initial_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, meta = toy_experiment.generate_events(n=10_000, gamma=0, gen_volume=\"box\", e_lim=(1,7), inelast_lim=(0,1),\n",
    "                                              x_lim=(-7,7), y_lim=(-2, 2), z_lim=(0,0), t_width=0, coszen_lim=(1,1),\n",
    "                                              contained=False, min_hits=3) #, rand=1\n",
    "truths = NNs.make_truth_array(events)\n",
    "#np.save('recos/simple_toy/truths', truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLH_ana(X, hits, n_obs, form='total', fix=[None], bounds=bounds):\n",
    "    if fix[0] != None:\n",
    "        X = np.insert(X, fix[0], fix[1])\n",
    "\n",
    "    if ~np.alltrue(np.logical_and(bounds[:,0] <= X, X <= bounds[:,1]), axis=-1):\n",
    "        return 1e9\n",
    "    \n",
    "    segments = toy_experiment.model(*X)\n",
    "    if form == 'dom':\n",
    "        h_term = toy_experiment.nllh_p_term_dom(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_dom(segments, n_obs)\n",
    "    elif form == 'total':\n",
    "        h_term = toy_experiment.nllh_p_term_tot(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_tot(segments, n_obs)\n",
    "    else:\n",
    "        raise NameError(\"Formulation must be one of ['total', 'dom'], not \"+form)\n",
    "    \n",
    "    return c_term + h_term\n",
    "\n",
    "def fit_event_ana(event):\n",
    "    hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'sensor_id']], axis=1)\n",
    "    n_obs = event.n_obs.to_numpy() \n",
    "    #truth = event?\n",
    "    \n",
    "    def eval_LLH(params):\n",
    "        llhs = []\n",
    "        for p in params:\n",
    "            llhs.append(LLH_ana(p, hits, n_obs)) #, fix=[[2, 5], [0, 0]]\n",
    "        return np.array(llhs)\n",
    "\n",
    "    # seeding\n",
    "    initial_points = init_points(hits, 97) #, seed=truth\n",
    "    \n",
    "    # free fit\n",
    "    fit_res = spherical_opt.spherical_opt(\n",
    "        func=eval_LLH,\n",
    "        method=\"CRS2\",\n",
    "        initial_points=initial_points,\n",
    "        rand=np.random.default_rng(42),            \n",
    "        spherical_indices=[[4,5]],\n",
    "        batch_size=12,\n",
    "    )\n",
    "\n",
    "    return list(np.delete(fit_res['x'], [2, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(10) as p:\n",
    "    outs = p.map(fit_event_ana, events)\n",
    "recos_ana = np.array(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = recos_ana - np.delete(truths, [2, 4, 5], axis=1)\n",
    "#np.save('recos/simple_toy/diff_ana', diff_ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "from freedom.llh_service.llh_service import LLHService\n",
    "from freedom.llh_service.llh_client import LLHClient\n",
    "from freedom.reco import crs_reco\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE, Set = 2_560_000 , 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'networks/simple_toy/'\n",
    "service_conf = {\n",
    "        \"poll_timeout\": 1,\n",
    "        \"flush_period\": 1,\n",
    "        \"n_hypo_params\": 8,\n",
    "        \"n_hit_features\": 6,\n",
    "        \"n_evt_features\": 2, #len(detector)*4,\n",
    "        \"batch_size\" : {\n",
    "          \"n_hypos\": 200,\n",
    "          \"n_observations\": 6000, \n",
    "        },\n",
    "        \"send_hwm\": 10000,\n",
    "        \"recv_hwm\": 10000,\n",
    "        #\"hitnet_file\": loc+'%s/simple_toy_hitnet_total_%s_set%s.h5'%(NE, NE, Set),\n",
    "        \"chargenet_file\": loc+'%s/simple_toy_chargenet_total_%s_set%s.h5'%(NE, NE, Set),\n",
    "        \"hitnet_file\": loc+'/simple_toy_hitnet_total_noTsmear.h5',\n",
    "        #\"chargenet_file\": loc+'/simple_toy_chargenet_total_large.h5',\n",
    "        #\"hitnet_file\": loc+'simple_toy_hitnet_dom.h5',\n",
    "        #\"domnet_file\": loc+'simple_toy_chargenet_dom.h5',\n",
    "        #\"ndoms\": len(detector),\n",
    "        \"toy\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 4\n",
    "\n",
    "base_req = \"ipc:///tmp/recotestreq\"\n",
    "base_ctrl = \"ipc:///tmp/recotestctrl\"\n",
    "\n",
    "req_addrs = []\n",
    "ctrl_addrs = []\n",
    "for i in range(n_gpus):\n",
    "    req_addrs.append(f'{base_req}{i}')\n",
    "    ctrl_addrs.append(f'{base_ctrl}{i}')\n",
    "    \n",
    "procs = []\n",
    "for i in range(n_gpus):\n",
    "    proc = Process(target=crs_reco.start_service, args=(service_conf, ctrl_addrs[i], req_addrs[i], i))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_events_nn(events, index, Truths, ctrl_addrs):\n",
    "    outputs = []\n",
    "\n",
    "    client = LLHClient(ctrl_addr=ctrl_addrs[index], conf_timeout=60000)\n",
    "    def Eval_llh(params, hits, n_obs, fix=[None]):\n",
    "        if fix[0] != None:\n",
    "            params = np.insert(params, fix[0], fix[1])\n",
    "            \n",
    "        if ~np.alltrue(np.logical_and(bounds[:,0] <= params, params <= bounds[:,1]), axis=-1):\n",
    "            return 1e9\n",
    "        \n",
    "        c_data = [np.sum(n_obs), np.sum(n_obs > 0)] #total\n",
    "        #c_data = np.hstack([detector, n_obs[:, np.newaxis]]) #dom\n",
    "        #ps = np.array(params)\n",
    "        #ps[-2], ps[-1] = ps[-2] * ps[-1], ps[-2] * (1-ps[-1])\n",
    "        return client.eval_llh(hits, c_data, params)\n",
    "\n",
    "    for j, event in enumerate(events):\n",
    "        hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'q', 'sensor_id']], axis=1)\n",
    "        n_obs = event.n_obs.to_numpy()\n",
    "        \n",
    "        def eval_LLH(params):\n",
    "            if params.ndim == 1:\n",
    "                return Eval_llh(params, hits, n_obs) #, fix=[[2, 5], [0, 0]]\n",
    "            else:\n",
    "                o = []\n",
    "                for p in params:\n",
    "                    o.append(Eval_llh(p, hits, n_obs)) #, fix=[[2, 5], [0, 0]]\n",
    "                return np.array(o)\n",
    "\n",
    "        # seeding\n",
    "        initial_points = init_points(hits, 97) #, seed=Truths[j]\n",
    "        \n",
    "        #free fit\n",
    "        fit_res = spherical_opt.spherical_opt(\n",
    "            func=eval_LLH,\n",
    "            method=\"CRS2\",\n",
    "            initial_points=initial_points,\n",
    "            rand=np.random.default_rng(42),            \n",
    "            spherical_indices=[[4,5]],\n",
    "            batch_size=12,\n",
    "        )\n",
    "        outputs.append(np.delete(fit_res['x'], [2, 4, 5]))\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = len(events)\n",
    "pool_size = 200\n",
    "evts_per_proc = int(math.ceil(events_to_process/pool_size))\n",
    "evt_splits = [events[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "true_splits = [truths[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "print(sum(len(l) for l in evt_splits))\n",
    "\n",
    "gpu_inds = np.arange(pool_size) % n_gpus\n",
    "\n",
    "fit_events_partial = partial(\n",
    "        fit_events_nn,\n",
    "        ctrl_addrs=ctrl_addrs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reconstruct with a worker pool; one LLH client per worker\n",
    "with Pool(pool_size) as p:\n",
    "    outs = p.starmap(fit_events_partial, zip(evt_splits, gpu_inds, true_splits))\n",
    "\n",
    "all_outs = sum((out for out in outs), [])\n",
    "all_outs = np.array(all_outs).reshape((events_to_process, 5))\n",
    "recos_nn = np.array(all_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_nn = recos_nn - np.delete(truths, [2, 4, 5], axis=1)\n",
    "#np.save('recos/simple_toy/%s/diff_nn_%s_set%s'%(NE, NE, Set), diff_nn)\n",
    "#np.save('recos/simple_toy/diff_nn_noTsmear', diff_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all the services\n",
    "import zmq\n",
    "for proc, ctrl_addr in zip(procs, ctrl_addrs): \n",
    "    with zmq.Context.instance().socket(zmq.REQ) as ctrl_sock:\n",
    "        ctrl_sock.connect(ctrl_addr)\n",
    "        ctrl_sock.send_string(\"die\")\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truths = np.load('recos/simple_toy/truths.npy')\n",
    "#truths_2 = np.load('recos/simple_toy/truths_2.npy')\n",
    "diff_ana = np.load('recos/simple_toy/diff_ana.npy')\n",
    "diff_ana2 = np.load('recos/simple_toy/diff_ana2.npy')\n",
    "diff_ana_2 = np.load('recos/simple_toy/diff_ana_2.npy')\n",
    "data_sizes = np.load('recos/simple_toy/data_sizes.npy')\n",
    "\n",
    "#NEs = np.array([10000, 20000, 40000, 80000, 160000, 320000, 640000, 1280000, 2560000])\n",
    "NEs = np.array([10000, 40000, 160000, 640000, 2560000])\n",
    "\n",
    "for NE in NEs:\n",
    "    exec(\"diff_nn_%s = np.load('recos/simple_toy/%s/diff_nn_%s.npy')\"%(NE, NE, NE))\n",
    "    exec(\"diff_nn_%s_big = np.load('recos/simple_toy/%s/diff_nn_%s_big.npy')\"%(NE, NE, NE))\n",
    "    exec(\"diff_nn_%s_small = np.load('recos/simple_toy/%s/diff_nn_%s_small.npy')\"%(NE, NE, NE))\n",
    "\n",
    "#diff_nn_1280000_2 = np.load('recos/simple_toy/1280000/diff_nn_1280000_2.npy')\n",
    "#diff_nn_1280000_3 = np.load('recos/simple_toy/1280000/diff_nn_1280000_3.npy')\n",
    "#diff_nn_1280000_4 = np.load('recos/simple_toy/1280000/diff_nn_1280000_4.npy')\n",
    "#diff_nn_1280000_5 = np.load('recos/simple_toy/1280000/diff_nn_1280000_5.npy')\n",
    "\n",
    "for s in [1,2,3,4]:\n",
    "    for NE in NEs:\n",
    "        exec(\"diff_nn_%s_set%s = np.load('recos/simple_toy/%s/diff_nn_%s_set%s.npy')\"%(NE, s, NE, NE, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ranges = [(-2.5,2.5), (-4,4), (-15,20), (-5,5), (-1,1)]\n",
    "for i, p in enumerate([0,1,3,6,7]):\n",
    "    bins = np.linspace(ranges[i][0], ranges[i][1], 101)\n",
    "    \n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.hist(diff_ana[:, i], bins, label='Analytic', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_10000[:, i], bins, label='NN_10k', histtype='step', linewidth=2) #, alpha=0.2\n",
    "    #plt.hist(diff_nn_20000[:, i], bins, label='NN_20k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_40000[:, i], bins, label='NN_40k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_80000[:, i], bins, label='NN_80k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_160000[:, i], bins, label='NN_160k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_320000[:, i], bins, label='NN_320k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_640000[:, i], bins, label='NN_640k', histtype='step', linewidth=2)\n",
    "    #plt.hist(diff_nn_1280000[:, i], bins, label='NN_1.28m', histtype='step', linewidth=2)\n",
    "    plt.hist(diff_nn_2560000[:, i], bins, label='NN_2.56m', histtype='step', linewidth=2)\n",
    "    plt.hist(diff_nn[:, i], bins, label='NN', histtype='step', linewidth=2)\n",
    "    #plt.hist(recos_ana[:, i], 50, alpha=0.5, label='Analytic')\n",
    "    #plt.hist(recos_nn[:, i], 50, alpha=0.5, label='NN')\n",
    "    if i == 1: plt.title('Reco-Truth')\n",
    "    if i == 2: plt.legend()\n",
    "    plt.xlabel(par_names[p])\n",
    "    \n",
    "#plt.savefig('images/simple_tests/simple_reco_big_best.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "iqr_ana = stats.iqr(diff_ana, axis=0)\n",
    "plt.scatter(range(5), iqr_ana/iqr_ana, label='Analytic')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_10000, axis=0)/iqr_ana, label='NN_10k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_20000, axis=0)/iqr_ana, label='NN_20k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_40000, axis=0)/iqr_ana, label='NN_40k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_80000, axis=0)/iqr_ana, label='NN_80k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_160000, axis=0)/iqr_ana, label='NN_160k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_320000, axis=0)/iqr_ana, label='NN_320k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_640000, axis=0)/iqr_ana, label='NN_640k')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_1280000, axis=0)/iqr_ana, label='NN_1.28m')\n",
    "plt.scatter(range(5), stats.iqr(diff_nn_2560000, axis=0)/iqr_ana, label='NN_2.56m')\n",
    "\n",
    "plt.xticks(range(5), np.array(par_names)[[0,1,3,6,7]])\n",
    "plt.ylabel('IQR Reco-Truth / Analytic')\n",
    "plt.ylim(0.93,1.3)\n",
    "\n",
    "plt.subplot(122)\n",
    "med_ana = np.median(np.abs(diff_ana), axis=0)\n",
    "plt.scatter(range(5), med_ana/med_ana, label='Analytic')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_10000), axis=0)/med_ana, label='NN_10k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_20000), axis=0)/med_ana, label='NN_20k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_40000), axis=0)/med_ana, label='NN_40k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_80000), axis=0)/med_ana, label='NN_80k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_160000), axis=0)/med_ana, label='NN_160k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_320000), axis=0)/med_ana, label='NN_320k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_640000), axis=0)/med_ana, label='NN_640k')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_1280000), axis=0)/med_ana, label='NN_1.28m')\n",
    "plt.scatter(range(5), np.median(np.abs(diff_nn_2560000), axis=0)/med_ana, label='NN_2.56m')\n",
    "\n",
    "plt.xticks(range(5), np.array(par_names)[[0,1,3,6,7]])\n",
    "plt.legend()\n",
    "plt.ylabel('Median absolute Reco-Truth / Analytic')\n",
    "plt.ylim(0.93,1.3)\n",
    "\n",
    "#plt.savefig('images/simple_tests/simple_reco_iqr_med2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ks results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_ana2, ks_ana_2 = [], []\n",
    "for i in range(5):\n",
    "    ks_ana2.append(stats.ks_2samp(diff_ana[:,i], diff_ana2[:,i])[0])\n",
    "    ks_ana_2.append(stats.ks_2samp(diff_ana[:,i], diff_ana_2[:,i])[0])\n",
    "    \n",
    "#ks = []\n",
    "#for i in range(5):\n",
    "#    ks.append(stats.ks_2samp(diff_ana[:,i], diff_nn[:,i])[0])\n",
    "\n",
    "kss, kss_big, kss_small = np.zeros((5,len(NEs),5)), np.zeros((len(NEs),5)), np.zeros((len(NEs),5))\n",
    "for j, NE in enumerate(NEs):\n",
    "    exec('diff = diff_nn_'+str(NE))\n",
    "    for i in range(5):\n",
    "        kss[0][j][i] = stats.ks_2samp(diff_ana[:,i], diff[:,i])[0]\n",
    "        \n",
    "    exec('diff = diff_nn_'+str(NE)+'_big')\n",
    "    for i in range(5):\n",
    "        kss_big[j][i] = stats.ks_2samp(diff_ana[:,i], diff[:,i])[0]\n",
    "        \n",
    "    exec('diff = diff_nn_'+str(NE)+'_small')\n",
    "    for i in range(5):\n",
    "        kss_small[j][i] = stats.ks_2samp(diff_ana[:,i], diff[:,i])[0]\n",
    "    \n",
    "for s in [1,2,3,4]:\n",
    "    for j, NE in enumerate(NEs):\n",
    "        exec('diff = diff_nn_'+str(NE)+'_set'+str(s))\n",
    "        for i in range(5):\n",
    "            kss[s][j][i] = stats.ks_2samp(diff_ana[:,i], diff[:,i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(np.vstack([np.mean(kss_big, axis=1), np.mean(kss[0], axis=1), np.mean(kss_small, axis=1)]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 8*0.618))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "for i, p in enumerate([0,1,3,6,7]):\n",
    "    ax1.scatter(NEs, kss[0][:,i], alpha=0.5, label=par_names[p])\n",
    "ax1.scatter(NEs, np.mean(kss[0], axis=1), label='Average', color='black')\n",
    "\n",
    "#ax1.scatter(NEs, np.mean(kss_big, axis=1), label='Average big NN', color='black', marker='*')\n",
    "#ax1.scatter(NEs, np.mean(kss_small, axis=1), label='Average small NN', color='black', marker='s')\n",
    "\n",
    "ax1.axhline(np.mean(ks_ana2), color='black', linestyle='--', label=r'KS$_{rereco}$')\n",
    "#ax1.axhline(np.mean(ks_ana_2), color='grey', linestyle=':', alpha=0.7, label='new events (ana)')\n",
    "\n",
    "ax2.set_xlabel('Data size (GB)')\n",
    "ax2.scatter(data_sizes[::2]*1e-9, np.mean(kss[0], axis=1), marker='')\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "ax1.legend(prop={'size':15})\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('#Events in training set')\n",
    "ax1.set_ylabel('KS value')\n",
    "\n",
    "#plt.savefig('images/simple_tests/simple_reco_ks.png', bbox_inches='tight') #_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 8*0.618))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "ax1.errorbar(NEs, np.mean(np.mean(kss, axis=2), axis=0), np.std(np.mean(kss, axis=2), axis=0), \n",
    "             label='Average all sets', color='black')\n",
    "for i, a in enumerate(np.mean(kss, axis=2)):\n",
    "    ax1.scatter(NEs, a, label='Average set '+str(i))\n",
    "\n",
    "ax1.axhline(np.mean(ks_ana2), color='black', linestyle='--', label=r'KS$_{rereco}$')\n",
    "#ax1.axhline(np.mean(ks_ana_2), color='grey', linestyle=':', alpha=0.7, label='new events (ana)')\n",
    "#ax1.axhline(np.mean(ks), color='black', linestyle='--', label=r'KS$_{large}$')\n",
    "\n",
    "ax2.set_xlabel('Data size (GB)')\n",
    "ax2.scatter(data_sizes[::2]*1e-9, np.mean(kss[0], axis=1), marker='')\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "ax1.legend(prop={'size':15}, loc='upper right')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('#Events in training set')\n",
    "ax1.set_ylabel('KS value')\n",
    "plt.ylim(0, 0.27)\n",
    "\n",
    "#plt.savefig('images/simple_tests/simple_reco_ks_avg_sets.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, a, b):\n",
    "    return a/np.log(b*x) + np.mean(ks_ana2)\n",
    "def lin(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "x = NEs\n",
    "y = np.mean(np.mean(kss, axis=2), axis=0)\n",
    "\n",
    "fit, cov = curve_fit(func, x, y, sigma=np.std(np.mean(kss, axis=2), axis=0), p0=[0.3, 5e-4])\n",
    "fit2, cov = curve_fit(lin, x, data_sizes[::2], p0=[4000, 4e5])\n",
    "ps = np.logspace(3.9,9,100)\n",
    "fit, fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 8*0.618))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "ax1.errorbar(NEs, np.mean(np.mean(kss, axis=2), axis=0), np.std(np.mean(kss, axis=2), axis=0), \n",
    "             label='Average all sets', color='black')\n",
    "ax1.axhline(np.mean(ks_ana2), color='black', linestyle='--', label=r'KS$_{rereco}$')\n",
    "ax1.plot(ps, func(ps, fit[0], fit[1]), label=r'$\\frac{a}{\\log(b\\cdot x)}+KS_{rereco}$')\n",
    "\n",
    "ax2.set_xlabel('Data size (GB)')\n",
    "ax2.scatter(lin(ps, fit2[0], fit2[1])*1e-9, np.zeros(len(ps)), marker='')\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "ax1.legend(prop={'size':15})\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('#Events in training set')\n",
    "ax1.set_ylabel('KS value')\n",
    "\n",
    "#plt.savefig('images/simple_tests/simple_reco_ks_avg_fit.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error per pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IDX = (6,7)\n",
    "for NE in NEs:\n",
    "    exec('diff = diff_nn_'+str(NE))\n",
    "    \n",
    "    fig = plt.figure(figsize=(22, 10))\n",
    "    for i, p in enumerate([0,1,3,6,7]):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        idx = np.abs(diff[:,i]).argsort()\n",
    "\n",
    "        plt.scatter(truths[idx,IDX[0]], truths[idx,IDX[1]], c=np.abs(diff[idx,i]), s=12)\n",
    "        cbar=plt.colorbar()\n",
    "        cbar.set_label('Absolute ' + par_names[p] + ' error')\n",
    "        #plt.scatter(np.linspace(-5,5,5), np.zeros(5), color='red')\n",
    "\n",
    "        if i==1: plt.title('Resolution depending on true position (%s)'%(NE))\n",
    "        plt.xlabel(par_names[IDX[0]])\n",
    "        plt.ylabel(par_names[IDX[1]])\n",
    "\n",
    "    pname = par_names[IDX[0]]+par_names[IDX[1]]\n",
    "    #plt.savefig('images/simple_tests/simple_resolutions_'+pname+'_'+str(NE)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
