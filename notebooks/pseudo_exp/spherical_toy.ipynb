{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dama as dm\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import awkward as ak\n",
    "\n",
    "from freedom.toy_model.toy_model_functions import toy_model\n",
    "from freedom.toy_model.detectors import get_spherical_detector\n",
    "from types import SimpleNamespace\n",
    "from freedom.toy_model import NNs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16 \n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "\n",
    "par_names = ['x', 'y', 'z', 't', 'azi', 'zen', 'E', 'trck_frac']\n",
    "\n",
    "def plot_truth(axes, truth, idx=(0,1)):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([truth[idx[0]]], [truth[idx[1]]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, limit_diff=False, **kwargs):\n",
    "    \n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    #a.plot(ax=axes[0], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    a.plot_contour(ax=axes[0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[0].set_title(title_a)\n",
    "    #b.plot(ax=axes[1], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    b.plot_contour(ax=axes[1], levels=levels,  labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    if limit_diff:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-vmax, vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #np.clip(-diff, 0, None).plot_contour(ax=axes[2], levels=[0.1,0.2, 0.3], colors=['r']*2)\n",
    "    else:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)), label=r'$\\Delta LLH$', **kwargs) \n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[2].set_title(title_a + ' - ' + title_b)\n",
    "    \n",
    "def correct_azi(azi):\n",
    "    azi = np.where(azi<-np.pi, azi+2*np.pi, azi)\n",
    "    return np.where(azi>np.pi, azi-2*np.pi, azi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = get_spherical_detector(radius=10, subdivisions=4)\n",
    "print(len(detector))\n",
    "\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(detector[:,0], detector[:,1], detector[:,2], color='black', s=50)\n",
    "ax.grid(False)\n",
    "#ax.scatter(3., 1., 0.)\n",
    "#plt.savefig('images/spherical_det.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([3., 1., 0, 0, 0, np.arccos(1), 5., 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid scan\n",
    "\n",
    "g = dm.GridData(x=np.linspace(-10, 10, 100), y=np.linspace(-10, 10, 100))\n",
    "IDX = (0,1)\n",
    "\n",
    "g['dom_hit_term'] = np.empty(g.shape)\n",
    "g['dom_charge_terms'] = np.empty(g.shape)\n",
    "g['total_charge_hit_terms'] = np.empty(g.shape)\n",
    "g['total_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g.shape):\n",
    "    p[IDX[0]] = g['x'][idx]\n",
    "    p[IDX[1]] = g['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    g['total_charge_hit_terms'][idx] = toy_experiment.nllh_p_term_tot(segments, test_event[0])\n",
    "    g['total_charge_terms'][idx] = toy_experiment.nllh_N_term_tot(segments, test_event[1])\n",
    "    \n",
    "g['dom_hit_term'] -= g['dom_hit_term'].min()\n",
    "g['dom_charge_terms'] -= g['dom_charge_terms'].min()\n",
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['total_charge_hit_terms'] -= g['total_charge_hit_terms'].min()\n",
    "g['total_charge_terms'] -= g['total_charge_terms'].min()\n",
    "g['total_charge_llh'] = g['total_charge_hit_terms'] + g['total_charge_terms']\n",
    "g['dom_llh'] -= g['dom_llh'].min()\n",
    "g['total_charge_llh'] -= g['total_charge_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "plot_diff(g['dom_hit_term'], g['total_charge_hit_terms'], axes=ax[0], title_a='per DOM hit', title_b='total hit', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_charge_terms'], g['total_charge_terms'], axes=ax[1], title_a='per DOM charge', title_b='total charge', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_llh'], g['total_charge_llh'], axes=ax[2], title_a='per DOM llh', title_b='total llh', limit_diff=False)\n",
    "\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/LLH_decompose.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE, Set = 100_000, 3\n",
    "events, meta = toy_experiment.generate_events(n=NE, gamma=0, gen_volume=\"sphere\", e_lim=(1,12), inelast_lim=(0,1),\n",
    "                                              t_width=0, radius=10, contained=True, min_hits=3, rand=Set)\n",
    "#truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(x), del(t)\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, time_spread=10)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, time_spread=10)\n",
    "\n",
    "#d_train = NNs.DataGenerator(train_test_split(ak.ravel(events.photons[['x', 'y', 'z', 't', 'q', 'sensor_id']]).to_numpy().reshape(6, -1).T, test_size=1, random_state=42)[0],\n",
    "#                            train_test_split(np.repeat(NNs.make_truth_array(events), ak.count(events.photons.t, axis=1).to_numpy(), axis=0), test_size=1, random_state=42)[0], \n",
    "#                            batch_size=4096*nGPUs, time_spread=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel_t = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    #hmodel_t = tf.keras.models.load_model('networks/spherical/spherical_toy_hitnet_total3.h5',\n",
    "    #                                      custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})\n",
    "    hmodel_t.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel_t.fit(d_train, epochs=5, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel_t.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel_t.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel_t.compile()\n",
    "\n",
    "llhs = -hmodel_t((xxs, tts)).numpy()\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_total = llhs.reshape(g.shape)\n",
    "g.hit_llh_total -= g.hit_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, g.hit_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmodel_t.save('networks/spherical/'+str(NE)+'/spherical_toy_hitnet_total_'+str(NE)+'_set'+str(Set)+'.h5')\n",
    "#hmodel_t = tf.keras.models.load_model('networks/spherical/spherical_toy_hitnet_total.h5',\n",
    "#                                      custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_charge_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)\n",
    "\n",
    "#d_train = NNs.DataGenerator(train_test_split(np.stack([np.sum(events.n_obs.to_numpy(), axis=1), np.sum(events.n_obs.to_numpy()>0, axis=1)], axis=1), test_size=1, random_state=42)[0],\n",
    "#                            train_test_split(NNs.make_truth_array(events), test_size=1, random_state=42)[0],\n",
    "#                            batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4) #3\n",
    "\n",
    "with strategy.scope():\n",
    "    cmodel = NNs.get_cmodel(x_shape=2, t_shape=8, trafo=NNs.charge_trafo_3D, activation='swish', final_activation='swish')\n",
    "    #cmodel = tf.keras.models.load_model('networks/spherical/spherical_toy_chargenet_total3.h5',\n",
    "    #                                     custom_objects={'charge_trafo_3D':NNs.charge_trafo_3D})\n",
    "    cmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = cmodel.fit(d_train, epochs=70, verbose=1, validation_data=d_valid) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = cmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.tile([len(test_event[0]), len(np.unique(test_event[0][:,0]))], np.prod(g.shape))\n",
    "xxs = xxs.reshape(-1, 2)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "\n",
    "cmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "cmodel.compile()\n",
    "\n",
    "llhs = np.nan_to_num(-cmodel((xxs, tts)))\n",
    "\n",
    "g.charge_llh_total = llhs.reshape(g.shape)\n",
    "g.charge_llh_total -= g.charge_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.total_charge_terms, g.charge_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/chargeNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel.save('networks/spherical/'+str(NE)+'/spherical_toy_chargenet_total_'+str(NE)+'_set'+str(Set)+'.h5')\n",
    "#cmodel = tf.keras.models.load_model('networks/spherical/spherical_toy_chargenet_total.h5',\n",
    "#                                     custom_objects={'charge_trafo_3D':NNs.charge_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, \n",
    "          g.hit_llh_total, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "\n",
    "plot_diff(g.total_charge_terms, \n",
    "          g.charge_llh_total, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "\n",
    "ana, NN = g.total_charge_hit_terms+g.total_charge_terms, g.hit_llh_total+g.charge_llh_total\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "#plt.savefig('images/NNtest_totalC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - per dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, t = NNs.get_hit_data(events)\n",
    "#x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "#d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=10)\n",
    "#d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=10)\n",
    "\n",
    "d_train = NNs.DataGenerator(train_test_split(ak.ravel(events.photons[['x', 'y', 'z', 't', 'q', 'sensor_id']]).to_numpy().reshape(6, -1).T, test_size=1, random_state=42)[0],\n",
    "                            train_test_split(np.repeat(NNs.make_truth_array(events), ak.count(events.photons.t, axis=1).to_numpy(), axis=0), test_size=1, random_state=42)[0], \n",
    "                            batch_size=4096*nGPUs, shuffle='inDOM', time_spread=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "\n",
    "with strategy.scope():\n",
    "    #hmodel_d = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    hmodel_d = tf.keras.models.load_model('networks/spherical/spherical_toy_hitnet_dom3.h5',\n",
    "                                          custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})\n",
    "    hmodel_d.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel_d.fit(d_train, epochs=3, verbose=1) #, validation_data=d_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel_d.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel_d.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel_d.compile()\n",
    "\n",
    "llhs = -hmodel_d.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.hit_llh_dom -= g.hit_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_hit_term, g.hit_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel_d.save('networks/spherical/spherical_toy_hitnet_dom3.h5')\n",
    "hmodel_d = tf.keras.models.load_model('networks/spherical/spherical_toy_hitnet_dom.h5',\n",
    "                                      custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, t = NNs.get_dom_data(events, detector)\n",
    "#x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "#d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "#d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)\n",
    "\n",
    "d_train = NNs.DataGenerator(train_test_split(np.hstack([np.repeat(detector[np.newaxis, :], len(events), axis=0).reshape(-1, 3), ak.ravel(events.n_obs).to_numpy()[:, np.newaxis]]), test_size=1, random_state=42)[0],\n",
    "                            train_test_split(np.repeat(NNs.make_truth_array(events), len(detector), axis=0), test_size=1, random_state=42)[0], \n",
    "                            batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    #dmodel = NNs.get_hmodel(x_shape=4, t_shape=8, trafo=NNs.dom_trafo_3D, activation='swish', final_activation='swish')\n",
    "    dmodel = tf.keras.models.load_model('networks/spherical/spherical_toy_chargenet_dom3.h5',\n",
    "                                         custom_objects={'dom_trafo_3D':NNs.dom_trafo_3D})\n",
    "    dmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dmodel.fit(d_train, epochs=2, verbose=1) #, validation_data=d_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = dmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "dmodel.compile()\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g.charge_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.charge_llh_dom -= g.charge_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, g.charge_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmodel.save('networks/spherical/spherical_toy_chargenet_dom3.h5')\n",
    "dmodel = tf.keras.models.load_model('networks/spherical/spherical_toy_chargenet_dom.h5',\n",
    "                                     custom_objects={'dom_trafo_3D':NNs.dom_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.dom_hit_term, \n",
    "          g.hit_llh_dom, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, \n",
    "          g.charge_llh_dom, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "\n",
    "ana, NN = g.dom_hit_term+g.dom_charge_terms, g.hit_llh_dom+g.charge_llh_dom\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "#plt.savefig('images/NNtest_perDOM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay(a, b, ax, **kwargs):\n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    a.plot_contour(ax=ax, levels=levels, labels=labels, colors=colors, **kwargs)\n",
    "    b.plot_contour(ax=ax, levels=levels, linestyles=[':']*len(levels), colors=colors, **kwargs)\n",
    "    ax.plot([], [], label='Analytic', color='Tab:blue')\n",
    "    ax.plot([], [], label='NN', linestyle=':', color='Tab:blue')\n",
    "    ax.set_xlabel(par_names[IDX[0]])\n",
    "    ax.set_ylabel(par_names[IDX[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['llh_dom'] = g['hit_llh_dom'] + g['charge_llh_dom']\n",
    "g['llh_total'] = g['hit_llh_total'] + g['charge_llh_total']\n",
    "g['llh_dom'] -= g['llh_dom'].min()\n",
    "g['llh_total'] -= g['llh_total'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(20,12))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "ax[0][0].set_title('HitNet', size=20)\n",
    "plot_overlay(g.dom_hit_term, g.hit_llh_dom, ax[0][0])\n",
    "ax[0][0].text(g.x.min()-2.5, g.y.mean(), 'Per Sensor', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "ax[0][1].set_title('ChargeNet', size=20)\n",
    "plot_overlay(g.dom_charge_terms, g.charge_llh_dom, ax[0][1])\n",
    "\n",
    "ax[0][2].set_title('Complete LLH', size=20)\n",
    "plot_overlay(g.dom_llh, g.llh_dom, ax[0][2])\n",
    "ax[0][2].legend(loc='upper left')\n",
    "\n",
    "plot_overlay(g.total_charge_hit_terms, g.hit_llh_total, ax[1][0])\n",
    "ax[1][0].text(g.x.min()-2.5, g.y.mean(), 'Total Detector', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "plot_overlay(g.total_charge_terms, g.charge_llh_total, ax[1][1])\n",
    "\n",
    "plot_overlay(g.total_charge_llh, g.llh_total, ax[1][2])\n",
    "\n",
    "#plt.savefig('images/NNtest_spherical_xt.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_data(truth, vec, bins):\n",
    "    t = truth.reshape((1,8))\n",
    "    ts = np.repeat(t, len(hits), axis=0)\n",
    "\n",
    "    r_t = np.exp(hmodel_t.predict([hits, ts], batch_size=5000)).flatten()\n",
    "    r_d = np.exp(hmodel_d.predict([hits, ts], batch_size=5000)).flatten()\n",
    "\n",
    "    dists = distance.cdist(detector[:,:3], toy_experiment.model(*truth)[:,:3])\n",
    "    survive = toy_experiment.survival(dists)\n",
    "    hit_llh_p, hit_llh_ps = [], []\n",
    "    for b in bins:\n",
    "        mat = toy_experiment.pandel.pdf(b-dists*4.333, d=dists)\n",
    "        hit_llh_p.append(np.sum(np.sum(mat, axis=0) * vec))\n",
    "        hit_llh_ps.append(np.sum(np.sum(mat * survive, axis=0) * vec))\n",
    "    norm_p = np.sum(np.array(hit_llh_p)) * np.diff(bins)[0]\n",
    "    norm_ps = np.sum(np.array(hit_llh_ps)) * np.diff(bins)[0]\n",
    "    \n",
    "    return r_t, r_d, hit_llh_p, hit_llh_ps, norm_p, norm_ps\n",
    "\n",
    "def get_charge_data(truth, exp_bins, exp_bins_fine):\n",
    "    t = truth.reshape((1,8))\n",
    "    ts_t = np.repeat(t, len(charges_t), axis=0)\n",
    "    ts_d = np.repeat(t, len(charges_d), axis=0)\n",
    "\n",
    "    r_t = np.exp(cmodel.predict([charges_t, ts_t], batch_size=5000)).flatten()\n",
    "    r_d = np.exp(dmodel.predict([charges_d, ts_d], batch_size=5000)).flatten()\n",
    "\n",
    "    N_exp = toy_experiment.N_exp(toy_experiment.model(*truth))\n",
    "    dom_c_llh = np.zeros(len(exp_bins))\n",
    "    for N in N_exp:\n",
    "        dom_c_llh += stats.poisson.pmf(exp_bins, mu=N)\n",
    "        \n",
    "    return r_t, r_d, N_exp, dom_c_llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, meta = toy_experiment.generate_events(n=100_000, gamma=0, gen_volume=\"sphere\", e_lim=(1,12), inelast_lim=(0,1),\n",
    "                                              t_width=0, radius=10, contained=True, min_hits=3)\n",
    "truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_events = []\n",
    "#while len(test_events) < 10_000:\n",
    "#    e = toy_experiment.generate_event(truth)\n",
    "#    if len(e[0]) >= 3:\n",
    "#        test_events.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hitnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for i, e in enumerate(test_events):\n",
    "#    if i == 0:\n",
    "#        test_hits = e[0]\n",
    "#    else:\n",
    "#        test_hits = np.concatenate([test_hits, e[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hits = NNs.get_hit_data(events)[0]\n",
    "hits[:, 3] += np.random.normal(0, 10, len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-20,200,100)\n",
    "\n",
    "r_t, r_d, hit_llh_p, hit_llh_ps, norm_p, norm_ps = get_hit_data(\n",
    "                                                            np.array([3., 1., 0, 0, 0, np.arccos(1), 5., 0.8]), \n",
    "                                                            [4,0.2,0.2,0.2,0.2,0.2],\n",
    "                                                            bins)\n",
    "\n",
    "r_t2, r_d2, hit_llh_p2, hit_llh_ps2, norm_p2, norm_ps2 = get_hit_data(\n",
    "                                                            np.array([-5., 7., 0, 0, 0, np.arccos(1), 3., 1]), \n",
    "                                                            [3],\n",
    "                                                            bins)\n",
    "\n",
    "r_t3, r_d3, hit_llh_p3, hit_llh_ps3, norm_p3, norm_ps3 = get_hit_data(\n",
    "                                                            np.array([-5., 3., 0, 0, 0, np.arccos(1), 4., 0.9]), \n",
    "                                                            [3.6,0.2,0.2],\n",
    "                                                            bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7*0.618))\n",
    "\n",
    "plt.subplot(121)\n",
    "#plt.hist(test_hits[:, 3], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x)$', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps)/norm_ps, c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t2, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps2)/norm_ps2, c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_t3, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_ps3)/norm_ps3, c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('All-sensor')\n",
    "plt.xlabel(r'$x$ = Hit time')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "#plt.hist(test_hits[:, 3], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x)$', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_p)/norm_p, c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_d2, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_p2)/norm_p2, c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_d3, density=True, histtype='step')\n",
    "plt.plot(bins+np.diff(bins)[0]/2, np.array(hit_llh_p3)/norm_p3, c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Per-sensor')\n",
    "plt.xlabel(r'$x$ = Hit time')\n",
    "\n",
    "#plt.savefig('images/spherical/NNtest_spherical_rweight_time.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "h2 = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t2, density=True, histtype='step')\n",
    "h3 = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t3, density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(hit_llh_ps)[:-1]/norm_ps - h[0]), np.max(np.array(hit_llh_ps2)[:-1]/norm_ps2 - h2[0]), np.max(np.array(hit_llh_ps3)[:-1]/norm_ps3 - h3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d, density=True, histtype='step')\n",
    "h2 = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_d2, density=True, histtype='step')\n",
    "h3 = plt.hist(hits[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_d3, density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(hit_llh_p)[:-1]/norm_p - h[0]), np.max(np.array(hit_llh_p2)[:-1]/norm_p2 - h2[0]), np.max(np.array(hit_llh_p3)[:-1]/norm_p3 - h3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chargenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for i, e in enumerate(test_events):\n",
    "#    if i == 0:\n",
    "#        test_charges_t = [[np.sum(e[1]), np.sum(e[1] > 0)]]\n",
    "#        test_charges_d = np.append(detector, e[1].reshape(-1,1), axis=1)\n",
    "#    else:\n",
    "#        test_charges_t = np.concatenate([test_charges_t, [[np.sum(e[1]), np.sum(e[1] > 0)]]])\n",
    "#        test_charges_d = np.concatenate([test_charges_d, np.append(detector, e[1].reshape(-1,1), axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "charges_t = NNs.get_charge_data(events)[0]\n",
    "charges_d = NNs.get_dom_data(events, detector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_bins, exp_bins_fine = np.linspace(0,12,13), np.linspace(15,150,136)\n",
    "\n",
    "r_t, r_d, N_exp, dom_c_llh = get_charge_data(np.array([3., 1., 0, 0, 0, np.arccos(1), 5., 0.8]),\n",
    "                                             exp_bins, exp_bins_fine)\n",
    "r_t2, r_d2, N_exp2, dom_c_llh2 = get_charge_data(np.array([-1., 2., 0, 0, 0, np.arccos(1), 2., 1]),\n",
    "                                                 exp_bins, exp_bins_fine)\n",
    "r_t3, r_d3, N_exp3, dom_c_llh3 = get_charge_data(np.array([-7., 1., 0, 0, 0, np.arccos(0), 5., 0.8]),\n",
    "                                                 exp_bins, exp_bins_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7*0.618))\n",
    "\n",
    "plt.subplot(121)\n",
    "bins = np.linspace(15,149,68)\n",
    "#plt.hist(test_charges_t[:, 0], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(charges_t[:, 0], bins, label='p(x)', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp)), \n",
    "         c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_t2, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp2)), \n",
    "         c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_t3, density=True, histtype='step')\n",
    "plt.plot(exp_bins_fine+np.diff(exp_bins_fine)[0]/2, stats.poisson.pmf(exp_bins_fine, mu=np.sum(N_exp3)), \n",
    "         c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "plt.title('All-sensor')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x$ = Charge (total detector)')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "bins = np.linspace(0,12,13)\n",
    "#plt.hist(test_charges_d[:, 3], bins, label='Pulses example event', density=True, histtype='step')\n",
    "plt.hist(charges_d[:, 3], bins, label='p(x)', density=True, histtype='step', color='black')\n",
    "\n",
    "plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d, density=True, histtype='step')\n",
    "plt.plot(exp_bins+np.diff(exp_bins)[0]/2, dom_c_llh/len(N_exp), c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "\n",
    "plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_d2, density=True, histtype='step')\n",
    "plt.plot(exp_bins+np.diff(exp_bins)[0]/2, dom_c_llh2/len(N_exp2), c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "\n",
    "plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_d3, density=True, histtype='step')\n",
    "plt.plot(exp_bins+np.diff(exp_bins)[0]/2, dom_c_llh3/len(N_exp3), c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "\n",
    "plt.title('Per-sensor')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4, 2)\n",
    "plt.xlabel(r'$x$ = Charge (sensor)')\n",
    "\n",
    "#plt.savefig('images/spherical/NNtest_spherical_rweight_charge.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(15,149,68)\n",
    "h = plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t, density=True, histtype='step')\n",
    "h2 = plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t2, density=True, histtype='step')\n",
    "h3 = plt.hist(charges_t[:, 0], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_t3, density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(stats.poisson.pmf((bins[1:]+bins[:-1])/2, mu=np.sum(N_exp)) - h[0]),np.max(stats.poisson.pmf((bins[1:]+bins[:-1])/2, mu=np.sum(N_exp2)) - h2[0]), np.max(stats.poisson.pmf((bins[1:]+bins[:-1])/2, mu=np.sum(N_exp3)) - h3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,12,13)\n",
    "h = plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d, density=True, histtype='step')\n",
    "h2 = plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d2, density=True, histtype='step')\n",
    "h3 = plt.hist(charges_d[:, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d3, density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(dom_c_llh[:-1]/len(N_exp) - h[0]), np.max(dom_c_llh2[:-1]/len(N_exp2) - h2[0]), np.max(dom_c_llh3[:-1]/len(N_exp3) - h3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,13,14)\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.3)\n",
    "\n",
    "for i, n in enumerate([0,20,40,45,50,70,100,120,150]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    idx = len(detector)*np.array(range(len(events)))+n\n",
    "    #plt.hist(test_charges_d[idx, 3], bins, label='Pulses example event', density=True, histtype='step')\n",
    "    plt.hist(charges_d[idx, 3], bins, label='p(x)', density=True, histtype='step', color='black')\n",
    "    \n",
    "    plt.hist(charges_d[idx, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{1})$', weights=r_d[idx], density=True, histtype='step')\n",
    "    plt.plot(exp_bins+np.diff(exp_bins)[0]/2, stats.poisson.pmf(exp_bins, mu=N_exp[n]), \n",
    "             c='tab:blue', linestyle='--', label=r'$p(x|\\theta_{1})$')\n",
    "    \n",
    "    plt.hist(charges_d[idx, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{2})$', weights=r_d2[idx], density=True, histtype='step')\n",
    "    plt.plot(exp_bins+np.diff(exp_bins)[0]/2, stats.poisson.pmf(exp_bins, mu=N_exp2[n]), \n",
    "             c='tab:orange', linestyle='--', label=r'$p(x|\\theta_{2})$')\n",
    "    \n",
    "    plt.hist(charges_d[idx, 3], bins, label=r'$p(x) \\hat{r}(x,\\theta_{3})$', weights=r_d3[idx], density=True, histtype='step')\n",
    "    plt.plot(exp_bins+np.diff(exp_bins)[0]/2, stats.poisson.pmf(exp_bins, mu=N_exp3[n]), \n",
    "             c='tab:green', linestyle='--', label=r'$p(x|\\theta_{3})$')\n",
    "    \n",
    "    plt.title('DOM '+str(n))\n",
    "    if i == 2: plt.legend()\n",
    "    plt.yscale('log')\n",
    "    if i > 5: plt.xlabel(r'$x$ = Charge (sensor)')\n",
    "    if i%3 == 0: plt.ylabel('PDF')\n",
    "    plt.ylim(1e-6, 1e0)\n",
    "#plt.savefig('images/spherical/NNtest_spherical_rweight_charge_d.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical_opt import spherical_opt\n",
    "from multiprocessing import Pool, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[-9.5,9.5], [-9.5,9.5], [-9.5,9.5], [-200,200], [0,2*np.pi], [0,np.pi], [1,12], [0,1]])\n",
    "def in_bound(X, radius=9.5):\n",
    "    r = np.sqrt(np.sum(X[:3]**2))\n",
    "    r_end = np.sqrt(np.sum(toy_experiment.endpoint(*X)**2))\n",
    "    return (r<=radius) & (r_end<=radius) & (np.alltrue(np.logical_and(bounds[:,0] <= X, X <= bounds[:,1]), axis=-1))\n",
    "\n",
    "def init_points(hits, n_live_points, bound=bounds, seed=[None]):\n",
    "    if seed[0] == None:\n",
    "        avg = np.average(hits[:, :4], axis=0)\n",
    "        low_lims = np.concatenate([avg-np.array([3,3,3,40]), np.array([0,0,1,0])])\n",
    "        hig_lims = np.concatenate([avg+np.array([3,3,3,0]), np.array([2*np.pi,np.pi,12,1])])\n",
    "    else:\n",
    "        low_lims = seed - np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "        hig_lims = seed + np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "    \n",
    "    uniforms = np.random.uniform(size=(n_live_points, 8))\n",
    "    initial_points = low_lims + uniforms * (hig_lims - low_lims)\n",
    "    initial_points = np.clip(initial_points, bounds[:, 0], bounds[:, 1])\n",
    "    return initial_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, meta = toy_experiment.generate_events(n=10_000, gamma=0, gen_volume=\"sphere\", e_lim=(3,10), inelast_lim=(0,1),\n",
    "                                              t_width=0, radius=9.5, contained=True, min_hits=3)\n",
    "truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLH_ana(X, hits, n_obs, form='total', fix=[None], bounds=bounds):\n",
    "    if fix[0] != None:\n",
    "        X = np.insert(X, fix[0], fix[1])\n",
    "        \n",
    "    if not in_bound(X):\n",
    "        return 1e9\n",
    "    \n",
    "    segments = toy_experiment.model(*X)\n",
    "    if form == 'dom':\n",
    "        h_term = toy_experiment.nllh_p_term_dom(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_dom(segments, n_obs)\n",
    "    elif form == 'total':\n",
    "        h_term = toy_experiment.nllh_p_term_tot(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_tot(segments, n_obs)\n",
    "    else:\n",
    "        raise NameError(\"Formulation must be one of ['total', 'dom'], not \"+form)\n",
    "    \n",
    "    return c_term + h_term\n",
    "\n",
    "def fit_event_ana(event):\n",
    "    hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'sensor_id']], axis=1)\n",
    "    n_obs = event.n_obs.to_numpy() \n",
    "    #truth = event?\n",
    "    \n",
    "    def eval_LLH(params):\n",
    "        if params.ndim == 1:\n",
    "            return LLH_ana(params, hits, n_obs)\n",
    "        else:\n",
    "            llhs = []\n",
    "            for p in params:\n",
    "                llhs.append(LLH_ana(p, hits, n_obs))\n",
    "            return np.array(llhs)\n",
    "\n",
    "    # seeding\n",
    "    initial_points = init_points(hits, 97) #, seed=truth\n",
    "    \n",
    "    start = time.time()\n",
    "    # free fit\n",
    "    fit_res = spherical_opt.spherical_opt(\n",
    "        func=eval_LLH,\n",
    "        method=\"CRS2\",\n",
    "        initial_points=initial_points,\n",
    "        rand=np.random.default_rng(42),\n",
    "        spherical_indices=[[4,5]],\n",
    "        batch_size=12,\n",
    "    )\n",
    "    fit_res['x'] = np.append(fit_res['x'], time.time() - start)\n",
    "\n",
    "    return list(fit_res['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(10) as p:\n",
    "    outs = p.map(fit_event_ana, events)\n",
    "recos_ana = np.array(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = recos_ana[:, :8] - truths\n",
    "diff_ana[:, 6] = np.log10(recos_ana[:, 6] / truths[:, 6])\n",
    "#np.save('recos/spherical/diff_ana', diff_ana)\n",
    "#np.save('recos/spherical/time_ana', recos_ana[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "from freedom.llh_service.llh_service import LLHService\n",
    "from freedom.llh_service.llh_client import LLHClient\n",
    "from freedom.reco import crs_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE, Set = 100000, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'networks/spherical/'\n",
    "service_conf = {\n",
    "        \"poll_timeout\": 1,\n",
    "        \"flush_period\": 1,\n",
    "        \"n_hypo_params\": 8,\n",
    "        \"n_hit_features\": 6,\n",
    "        \"n_evt_features\": 2, #len(detector)*4, #\n",
    "        \"batch_size\" : {\n",
    "          \"n_hypos\": 200,\n",
    "          \"n_observations\": 6000, \n",
    "        },\n",
    "        \"send_hwm\": 10000,\n",
    "        \"recv_hwm\": 10000,\n",
    "        \"hitnet_file\": loc+'%s/spherical_toy_hitnet_total_%s_set%s.h5'%(NE, NE, Set),\n",
    "        \"chargenet_file\": loc+'%s/spherical_toy_chargenet_total_%s_set%s.h5'%(NE, NE, Set),\n",
    "        #\"hitnet_file\": loc+'spherical_toy_hitnet_dom.h5',\n",
    "        #\"domnet_file\": loc+'spherical_toy_chargenet_dom.h5',\n",
    "        #\"ndoms\": len(detector),\n",
    "        \"toy\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 4\n",
    "\n",
    "base_req = \"ipc:///tmp/recotestreq\"\n",
    "base_ctrl = \"ipc:///tmp/recotestctrl\"\n",
    "\n",
    "req_addrs = []\n",
    "ctrl_addrs = []\n",
    "for i in range(n_gpus):\n",
    "    req_addrs.append(f'{base_req}{i}')\n",
    "    ctrl_addrs.append(f'{base_ctrl}{i}')\n",
    "    \n",
    "procs = []\n",
    "for i in range(n_gpus):\n",
    "    proc = Process(target=crs_reco.start_service, args=(service_conf, ctrl_addrs[i], req_addrs[i], i))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_events_nn(events, index, Truths, ctrl_addrs):\n",
    "    outputs = []\n",
    "\n",
    "    client = LLHClient(ctrl_addr=ctrl_addrs[index], conf_timeout=60000)\n",
    "    def Eval_llh(params, hits, n_obs, fix=[None]):\n",
    "        if fix[0] != None:\n",
    "            params = np.insert(params, fix[0], fix[1])\n",
    "            \n",
    "        if not in_bound(params):\n",
    "            return 1e9\n",
    "        \n",
    "        c_data = [np.sum(n_obs), np.sum(n_obs > 0)] #total\n",
    "        #c_data = np.hstack([detector, n_obs[:, np.newaxis]]) #dom\n",
    "        return client.eval_llh(hits, c_data, params)\n",
    "\n",
    "    for j, event in enumerate(events):\n",
    "        hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'q', 'sensor_id']], axis=1)\n",
    "        n_obs = event.n_obs.to_numpy()\n",
    "        \n",
    "        def eval_LLH(params):\n",
    "            if params.ndim == 1:\n",
    "                return Eval_llh(params, hits, n_obs)\n",
    "            else:\n",
    "                o = []\n",
    "                for p in params:\n",
    "                    o.append(Eval_llh(p, hits, n_obs))\n",
    "                return np.array(o)\n",
    "\n",
    "        # seeding\n",
    "        initial_points = init_points(hits, 97) #, seed=Truths[j]\n",
    "        \n",
    "        start = time.time()\n",
    "        #free fit\n",
    "        fit_res = spherical_opt.spherical_opt(\n",
    "            func=eval_LLH,\n",
    "            method=\"CRS2\",\n",
    "            initial_points=initial_points,\n",
    "            rand=np.random.default_rng(42),\n",
    "            spherical_indices=[[4,5]],\n",
    "            batch_size=12,\n",
    "        )\n",
    "        outputs.append(np.append(fit_res['x'], time.time() - start)) #\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = len(events)\n",
    "pool_size = 200\n",
    "evts_per_proc = int(math.ceil(events_to_process/pool_size))\n",
    "evt_splits = [events[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "true_splits = [truths[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "print(sum(len(l) for l in evt_splits))\n",
    "\n",
    "gpu_inds = np.arange(pool_size) % n_gpus\n",
    "\n",
    "fit_events_partial = partial(\n",
    "        fit_events_nn,\n",
    "        ctrl_addrs=ctrl_addrs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reconstruct with a worker pool; one LLH client per worker\n",
    "with Pool(pool_size) as p:\n",
    "    outs = p.starmap(fit_events_partial, zip(evt_splits, gpu_inds, true_splits))\n",
    "\n",
    "all_outs = sum((out for out in outs), [])\n",
    "all_outs = np.array(all_outs).reshape((events_to_process, 9))\n",
    "recos_nn = np.array(all_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_nn = recos_nn[:, :8] - truths\n",
    "diff_nn[:, 6] = np.log10(recos_nn[:, 6] / truths[:, 6])\n",
    "np.save('recos/spherical/%s/diff_nn_total_%s_set%s'%(NE, NE, Set), diff_nn) #perDOM\n",
    "#np.save('recos/spherical/time_total', recos_nn[:,8]) #perDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all the services\n",
    "import zmq\n",
    "for proc, ctrl_addr in zip(procs, ctrl_addrs): \n",
    "    with zmq.Context.instance().socket(zmq.REQ) as ctrl_sock:\n",
    "        ctrl_sock.connect(ctrl_addr)\n",
    "        ctrl_sock.send_string(\"die\")\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = np.load('recos/spherical/diff_ana.npy')\n",
    "diff_ana2 = np.load('recos/spherical/diff_ana2.npy')\n",
    "#diff_nn_t = np.load('recos/spherical/diff_nn_total.npy')\n",
    "#diff_nn_d = np.load('recos/spherical/diff_nn_perDOM.npy')\n",
    "\n",
    "NEs = np.array([50000, 100000, 200000, 500000, 1000000, 1500000])\n",
    "\n",
    "for s in range(5):\n",
    "    for NE in NEs:\n",
    "        exec(\"diff_nn_%s_set%s = np.load('recos/spherical/%s/diff_nn_total_%s_set%s.npy')\"%(NE, s, NE, NE, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lims = [[-2,2],[-2,2],[-2,2],[-5,5],[-2*np.pi,2*np.pi],[-np.pi,np.pi],[-0.2,0.2],[-0.7,0.7]]\n",
    "\n",
    "fig = plt.figure(figsize=(25, 17))\n",
    "\n",
    "for i in range(8):\n",
    "    bins = np.linspace(lims[i][0], lims[i][1], 50)\n",
    "    \n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.hist(diff_ana[:, i], bins, label='Analytic', alpha=0.5, histtype='step', linewidth=3, density=True)\n",
    "    #plt.hist(diff_nn_t[:, i], bins, label='NN total', alpha=0.5, histtype='step', linewidth=3, density=True)\n",
    "    #plt.hist(diff_nn_d[:, i], bins, label='NN dom', alpha=0.5, histtype='step', linewidth=3, density=True)\n",
    "    plt.hist(diff_nn_1500000_set0[:, i], bins, label='NN', alpha=0.5, histtype='step', linewidth=3, density=True)\n",
    "    #plt.hist(recos_ana[:, i], 50, alpha=0.5, label='Analytic')\n",
    "    #plt.hist(recos_nn_t[:, i], 50, alpha=0.5, label='NN (total)')\n",
    "    #plt.hist(recos_nn_d[:, i], 50, alpha=0.5, label='NN (dom)')\n",
    "    if i == 2: plt.legend()\n",
    "    if i == 1: plt.title('Spherical Detector, Reco-True')\n",
    "    plt.xlabel(par_names[i])\n",
    "    \n",
    "#plt.savefig('images/spherical/spherical_reco', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ks results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_ana2 = []\n",
    "for i in range(8):\n",
    "    ks_ana2.append(stats.ks_2samp(diff_ana[:,i], diff_ana2[:,i])[0])\n",
    "\n",
    "kss = np.zeros((5,len(NEs),8))  \n",
    "for s in range(5):\n",
    "    for j, NE in enumerate(NEs):\n",
    "        exec('diff = diff_nn_'+str(NE)+'_set'+str(s))\n",
    "        for i in range(8):\n",
    "            kss[s][j][i] = stats.ks_2samp(diff_ana[:,i], diff[:,i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 8*0.618))\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax2 = ax1.twiny()\n",
    "\n",
    "ax1.errorbar(NEs, np.mean(np.mean(kss, axis=2), axis=0), np.std(np.mean(kss, axis=2), axis=0), \n",
    "             label='Average all sets', color='black')\n",
    "for i, a in enumerate(np.mean(kss, axis=2)):\n",
    "    ax1.scatter(NEs, a, label='Average set '+str(i)) #\n",
    "\n",
    "ax1.axhline(np.mean(ks_ana2), color='black', linestyle='--', label=r'KS$_{rereco}$')\n",
    "\n",
    "#ax2.set_xlabel('Data size (GB)')\n",
    "#ax2.scatter(data_sizes[::2]*1e-9, np.mean(kss[0], axis=1), marker='')\n",
    "#ax2.set_xscale('log')\n",
    "\n",
    "ax1.legend(prop={'size':15}, loc='upper right')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('#Events in training set')\n",
    "ax1.set_ylabel('KS value')\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "#plt.savefig('images/spherical/spherical_reco_ks_avg_sets.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "for i in range(8):\n",
    "    plt.scatter(NEs, kss[0][:,i], alpha=0.5, label=par_names[i])\n",
    "plt.scatter(NEs, np.mean(kss[0], axis=1), label='Average', color='black')\n",
    "plt.axhline(np.mean(ks_ana2), color='black', linestyle='--', label=r'KS$_{rereco}$')\n",
    "\n",
    "plt.legend(prop={'size':15})\n",
    "plt.xscale('log')\n",
    "plt.xlabel('#Events in training set')\n",
    "plt.ylabel('KS value')\n",
    "\n",
    "#plt.savefig('images/spherical/spherical_reco_ks.png', bbox_inches='tight') #_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_nn_t = recos_nn[:,8] #np.load('recos/spherical/time_total.npy')\n",
    "time_nn_d = np.load('recos/spherical/time_perDOM.npy')\n",
    "\n",
    "PD = dm.PointData({'time_t': time_nn_t[:1000],\n",
    "                   'time_d': time_nn_d,\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,100,1000)\n",
    "PD.kde(time_t=bins).density.plot(label='All-sensor (mean=%.1f s)'%(np.mean(PD.time_t)))\n",
    "PD.kde(time_d=bins).density.plot(label='Per-sensor (mean=%.1f s)'%(np.mean(PD.time_d)))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Reconstruction time (s)')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "#plt.savefig('images/spherical/timing_spherical', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hits = NNs.get_charge_data(events)[0][:,0]\n",
    "mean_hits = np.mean(n_hits)\n",
    "\n",
    "(mean_hits+len(detector))/(mean_hits+1), np.mean(time_nn_d)/np.mean(time_nn_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
