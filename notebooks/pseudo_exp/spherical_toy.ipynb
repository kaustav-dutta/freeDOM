{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dama as dm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from freedom.toy_model.toy_model_functions import toy_model\n",
    "from freedom.toy_model.detectors import get_spherical_detector\n",
    "from types import SimpleNamespace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14 \n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = get_spherical_detector(radius=10, subdivisions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([3., 1., 0, 0, 0, np.arccos(1), 10., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid scan\n",
    "\n",
    "g = dm.GridData(x=np.linspace(-5, 5, 100), y=np.linspace(0, 2, 100))\n",
    "\n",
    "g['dom_hit_term'] = np.empty(g.shape)\n",
    "g['dom_charge_terms'] = np.empty(g.shape)\n",
    "g['total_charge_hit_terms'] = np.empty(g.shape)\n",
    "g['total_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g.shape):\n",
    "    p[0] =  g['x'][idx]\n",
    "    p[1] =  g['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    g['total_charge_hit_terms'][idx] = toy_experiment.nllh_p_term_tot(segments, test_event[0])\n",
    "    g['total_charge_terms'][idx] = toy_experiment.nllh_N_term_tot(segments, test_event[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['dom_hit_term'] -= g['dom_hit_term'].min()\n",
    "g['dom_charge_terms'] -= g['dom_charge_terms'].min()\n",
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['total_charge_hit_terms'] -= g['total_charge_hit_terms'].min()\n",
    "g['total_charge_terms'] -= g['total_charge_terms'].min()\n",
    "g['total_charge_llh'] = g['total_charge_hit_terms'] + g['total_charge_terms']\n",
    "g['dom_llh'] -= g['dom_llh'].min()\n",
    "g['total_charge_llh'] -= g['total_charge_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_truth(axes, truth):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([truth[0]], [truth[1]], marker='$T$', markersize=10, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, limit_diff=False, **kwargs):\n",
    "    \n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    #a.plot(ax=axes[0], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    a.plot_contour(ax=axes[0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[0].set_title(title_a)\n",
    "    #b.plot(ax=axes[1], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    b.plot_contour(ax=axes[1], levels=levels,  labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    if limit_diff:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-vmax, vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #np.clip(-diff, 0, None).plot_contour(ax=axes[2], levels=[0.1,0.2, 0.3], colors=['r']*2)\n",
    "    else:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)), label=r'$\\Delta LLH$', **kwargs) \n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[2].set_title(title_a + ' - ' + title_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats.norm.isf(stats.chi2(df=2).sf(g['dom_llh']*2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "plot_diff(g['dom_hit_term'], g['total_charge_hit_terms'], axes=ax[0], title_a='per DOM hit', title_b='total hit', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_charge_terms'], g['total_charge_terms'], axes=ax[1], title_a='per DOM charge', title_b='total charge', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_llh'], g['total_charge_llh'], axes=ax[2], title_a='per DOM llh', title_b='total llh', limit_diff=False)\n",
    "\n",
    "plot_truth(ax, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freedom.toy_model import NNs\n",
    "%aimport freedom.toy_model.NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, truths = toy_experiment.generate_event_sphere(n=100_000, e_lim=(1,10), inelast_lim=(0,1),\n",
    "                                                      t_width=0, contained=True, radius=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events, truths)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, time_spread=50)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, time_spread=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel.fit(d_train, epochs=25, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_total = llhs.reshape(g.shape)\n",
    "\n",
    "g.hit_llh_total -= g.hit_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, g.hit_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel.save('networks/spherical_toy_hitnet_total.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_charge_data(events, truths)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "with strategy.scope():\n",
    "    cmodel = NNs.get_cmodel(x_shape=2, t_shape=8, trafo=NNs.charge_trafo_3D, activation='swish', final_activation='swish') #\n",
    "    cmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = cmodel.fit(d_train, epochs=150, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = cmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.tile([len(test_event[0]), len(np.unique(test_event[0][:,0]))], np.prod(g.shape))\n",
    "xxs = xxs.reshape(-1, 2)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "\n",
    "cmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "cmodel.compile()\n",
    "\n",
    "llhs = np.nan_to_num(-cmodel.predict((xxs, tts), batch_size=4096))\n",
    "\n",
    "g.charge_llh_total = llhs.reshape(g.shape)\n",
    "\n",
    "g.charge_llh_total -= g.charge_llh_total.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.total_charge_terms, g.charge_llh_total, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/chargeNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmodel.save('networks/spherical_toy_chargenet_total.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - total charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.total_charge_hit_terms, \n",
    "          g.hit_llh_total, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "plot_diff(g.total_charge_terms, \n",
    "          g.charge_llh_total, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "ana, NN = g.total_charge_hit_terms+g.total_charge_terms, g.hit_llh_total+g.charge_llh_total\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "#plt.savefig('images/NNtest_totalC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - per dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events, truths)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=50)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel.fit(d_train, epochs=8, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.hit_llh_dom -= g.hit_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_hit_term, g.hit_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel.save('networks/spherical_toy_hitnet_dom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_dom_data(events, truths, detector)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    dmodel = NNs.get_hmodel(x_shape=4, t_shape=8, trafo=NNs.dom_trafo_3D, activation='swish', final_activation='swish')\n",
    "    dmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dmodel.fit(d_train, epochs=10, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = dmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "dmodel.compile()\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g.charge_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.charge_llh_dom -= g.charge_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, g.charge_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmodel.save('networks/spherical_toy_chargenet_dom.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.dom_hit_term, \n",
    "          g.hit_llh_dom, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, \n",
    "          g.charge_llh_dom, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "ana, NN = g.dom_hit_term+g.dom_charge_terms, g.hit_llh_dom+g.charge_llh_dom\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "#plt.savefig('images/NNtest_perDOM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay(a, b, ax, **kwargs):\n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    a.plot_contour(ax=ax, levels=levels, labels=labels, colors=colors, **kwargs)\n",
    "    b.plot_contour(ax=ax, levels=levels, linestyles=[':']*len(levels), colors=colors, **kwargs)\n",
    "    ax.plot([], [], label='Analytic', color='Tab:blue')\n",
    "    ax.plot([], [], label='NN', linestyle=':', color='Tab:blue')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['llh_dom'] = g['hit_llh_dom'] + g['charge_llh_dom']\n",
    "g['llh_total'] = g['hit_llh_total'] + g['charge_llh_total']\n",
    "g['llh_dom'] -= g['llh_dom'].min()\n",
    "g['llh_total'] -= g['llh_total'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(20,12))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "ax[0][0].set_title('HitNet', size=20)\n",
    "plot_overlay(g.dom_hit_term, g.hit_llh_dom, ax[0][0])\n",
    "ax[0][0].text(-7.3, 1, 'Per Sensor', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "ax[0][1].set_title('ChargeNet', size=20)\n",
    "plot_overlay(g.dom_charge_terms, g.charge_llh_dom, ax[0][1])\n",
    "\n",
    "ax[0][2].set_title('Complete LLH', size=20)\n",
    "plot_overlay(g.dom_llh, g.llh_dom, ax[0][2])\n",
    "ax[0][2].legend(loc='upper left')\n",
    "\n",
    "plot_overlay(g.total_charge_hit_terms, g.hit_llh_total, ax[1][0])\n",
    "ax[1][0].text(-7.3, 1, 'Total Detector', rotation=90, size=20, ha='center', va='center')\n",
    "\n",
    "plot_overlay(g.total_charge_terms, g.charge_llh_total, ax[1][1])\n",
    "\n",
    "plot_overlay(g.total_charge_llh, g.llh_total, ax[1][2])\n",
    "\n",
    "#plt.savefig('images/NNtest_spherical.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical_opt import spherical_opt\n",
    "from multiprocessing import Pool, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[-9,9], [-9,9], [-9,9], [-200,200], [0,2*np.pi], [0,np.pi], [0,10], [0,10]])\n",
    "\n",
    "def init_points(hits, n_live_points, bound=bounds, seed=[None]):\n",
    "    if seed[0] == None:\n",
    "        avg = np.average(hits[:, :4], axis=0)\n",
    "        low_lims = np.concatenate([avg-np.array([3,3,3,40]), np.array([0,0,0,0])])\n",
    "        hig_lims = np.concatenate([avg+np.array([3,3,3,0]), np.array([2*np.pi,np.pi,10,10])])\n",
    "    else:\n",
    "        low_lims = seed - np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "        hig_lims = seed + np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "    \n",
    "    uniforms = np.random.uniform(size=(n_live_points, 8))\n",
    "    initial_points = low_lims + uniforms * (hig_lims - low_lims)\n",
    "    initial_points = np.clip(initial_points, bounds[:, 0], bounds[:, 1])\n",
    "    return initial_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, truths = toy_experiment.generate_event_sphere(n=1000, e_lim=(1,10), inelast_lim=(0,1),\n",
    "                                                      t_width=0, contained=True, radius=9, N_min=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLH_ana(X, event, form='total', fix=[None], bounds=bounds):\n",
    "    if fix[0] != None:\n",
    "        X = np.insert(X, fix[0], fix[1])\n",
    "        \n",
    "    if ~np.alltrue(np.logical_and(bounds[:,0] <= X, X <= bounds[:,1]), axis=-1):\n",
    "        return 1e9\n",
    "    \n",
    "    segments = toy_experiment.model(*X)\n",
    "    if form == 'dom':\n",
    "        h_term = toy_experiment.nllh_p_term_dom(segments, event[0])\n",
    "        c_term = toy_experiment.nllh_N_term_dom(segments, event[1])\n",
    "    elif form == 'total':\n",
    "        h_term = toy_experiment.nllh_p_term_tot(segments, event[0])\n",
    "        c_term = toy_experiment.nllh_N_term_tot(segments, event[1])\n",
    "    else:\n",
    "        raise NameError(\"Formulation must be one of ['total', 'dom'], not \"+form)\n",
    "    \n",
    "    return c_term + h_term\n",
    "\n",
    "def fit_event_ana(event):\n",
    "    event, truth = event\n",
    "    \n",
    "    def eval_LLH(params):\n",
    "        if params.ndim == 1:\n",
    "            return LLH_ana(params, event)\n",
    "        else:\n",
    "            llhs = []\n",
    "            for p in params:\n",
    "                llhs.append(LLH_ana(p, event))\n",
    "            return np.array(llhs)\n",
    "\n",
    "    # seeding\n",
    "    initial_points = init_points(event[0], 97) #, seed=truth\n",
    "    \n",
    "    # free fit\n",
    "    fit_res = spherical_opt.spherical_opt(\n",
    "        func=eval_LLH,\n",
    "        method=\"CRS2\",\n",
    "        initial_points=initial_points,\n",
    "        rand=np.random.default_rng(42),\n",
    "        spherical_indices=[[4,5]],\n",
    "        batch_size=12,\n",
    "    )\n",
    "\n",
    "    return list(fit_res['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(10) as p:\n",
    "    outs = p.map(fit_event_ana, zip(events, truths))\n",
    "recos_ana = np.array(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = recos_ana - truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "from freedom.llh_service.llh_service import LLHService\n",
    "from freedom.llh_service.llh_client import LLHClient\n",
    "from freedom.reco import crs_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'networks/'\n",
    "service_conf = {\n",
    "        \"poll_timeout\": 1,\n",
    "        \"flush_period\": 1,\n",
    "        \"n_hypo_params\": 8,\n",
    "        \"n_hit_features\": 6,\n",
    "        \"n_evt_features\": len(detector)*4, #2\n",
    "        \"batch_size\" : {\n",
    "          \"n_hypos\": 200,\n",
    "          \"n_observations\": 6000, \n",
    "        },\n",
    "        \"send_hwm\": 10000,\n",
    "        \"recv_hwm\": 10000,\n",
    "        #\"hitnet_file\": loc+'spherical_toy_hitnet_total.h5',\n",
    "        #\"chargenet_file\": loc+'spherical_toy_chargenet_total.h5',\n",
    "        \"hitnet_file\": loc+'spherical_toy_hitnet_dom.h5',\n",
    "        \"domnet_file\": loc+'spherical_toy_chargenet_dom.h5',\n",
    "        \"ndoms\": len(detector),\n",
    "        \"toy\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 4\n",
    "\n",
    "base_req = \"ipc:///tmp/recotestreq\"\n",
    "base_ctrl = \"ipc:///tmp/recotestctrl\"\n",
    "\n",
    "req_addrs = []\n",
    "ctrl_addrs = []\n",
    "for i in range(n_gpus):\n",
    "    req_addrs.append(f'{base_req}{i}')\n",
    "    ctrl_addrs.append(f'{base_ctrl}{i}')\n",
    "    \n",
    "procs = []\n",
    "for i in range(n_gpus):\n",
    "    proc = Process(target=crs_reco.start_service, args=(service_conf, ctrl_addrs[i], req_addrs[i], i))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_events_nn(events, index, Truths, ctrl_addrs):\n",
    "    outputs = []\n",
    "\n",
    "    client = LLHClient(ctrl_addr=ctrl_addrs[index], conf_timeout=60000)\n",
    "    def Eval_llh(params, event, fix=[None]):\n",
    "        if fix[0] != None:\n",
    "            params = np.insert(params, fix[0], fix[1])\n",
    "            \n",
    "        if ~np.alltrue(np.logical_and(bounds[:,0] <= params, params <= bounds[:,1]), axis=-1):\n",
    "            return 1e9\n",
    "        \n",
    "        #c_data = [np.sum(event[1]), np.sum(event[1] > 0)] #total\n",
    "        c_data, _ = NNs.get_dom_data(np.array([event]), np.ones((1,8)), detector) #dom\n",
    "        return client.eval_llh(event[0], c_data, params)\n",
    "\n",
    "    for j, event in enumerate(events):\n",
    "        def eval_LLH(params):\n",
    "            if params.ndim == 1:\n",
    "                return Eval_llh(params, event)\n",
    "            else:\n",
    "                o = []\n",
    "                for p in params:\n",
    "                    o.append(Eval_llh(p, event))\n",
    "                return np.array(o)\n",
    "\n",
    "        # seeding\n",
    "        initial_points = init_points(event[0], 97) #, seed=Truths[j]\n",
    "        \n",
    "        #free fit\n",
    "        fit_res = spherical_opt.spherical_opt(\n",
    "            func=eval_LLH,\n",
    "            method=\"CRS2\",\n",
    "            initial_points=initial_points,\n",
    "            rand=np.random.default_rng(42),\n",
    "            spherical_indices=[[4,5]],\n",
    "            batch_size=12,\n",
    "        )\n",
    "        outputs.append(fit_res['x'])\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = len(events)\n",
    "pool_size = 200\n",
    "evts_per_proc = int(math.ceil(events_to_process/pool_size))\n",
    "evt_splits = [events[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "true_splits = [truths[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "print(sum(len(l) for l in evt_splits))\n",
    "\n",
    "gpu_inds = np.arange(pool_size) % n_gpus\n",
    "\n",
    "fit_events_partial = partial(\n",
    "        fit_events_nn,\n",
    "        ctrl_addrs=ctrl_addrs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reconstruct with a worker pool; one LLH client per worker\n",
    "with Pool(pool_size) as p:\n",
    "    outs = p.starmap(fit_events_partial, zip(evt_splits, gpu_inds, true_splits))\n",
    "\n",
    "all_outs = sum((out for out in outs), [])\n",
    "all_outs = np.array(all_outs).reshape((events_to_process, 8))\n",
    "#recos_nn_t = np.array(all_outs)\n",
    "recos_nn_d = np.array(all_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_nn_t = recos_nn_t - truths\n",
    "diff_nn_d = recos_nn_d - truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all the services\n",
    "import zmq\n",
    "for proc, ctrl_addr in zip(procs, ctrl_addrs): \n",
    "    with zmq.Context.instance().socket(zmq.REQ) as ctrl_sock:\n",
    "        ctrl_sock.connect(ctrl_addr)\n",
    "        ctrl_sock.send_string(\"die\")\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_names = ['x', 'y', 'z', 't', 'azi', 'zen', 'Ecscd', 'Etrck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 17))\n",
    "\n",
    "for i in range(8):\n",
    "    r = bounds[i][1] + 0.5*bounds[i][0]\n",
    "    bins = np.linspace(-r, r, 50)\n",
    "    \n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.hist(diff_ana[:, i], bins, alpha=0.5, label='Analytic')\n",
    "    plt.hist(diff_nn_t[:, i], bins, alpha=0.5, label='NN (total)')\n",
    "    plt.hist(diff_nn_d[:, i], bins, alpha=0.5, label='NN (dom)')\n",
    "    #plt.hist(recos_ana[:, i], 50, alpha=0.5, label='Analytic')\n",
    "    #plt.hist(recos_nn_t[:, i], 50, alpha=0.5, label='NN (total)')\n",
    "    #plt.hist(recos_nn_d[:, i], 50, alpha=0.5, label='NN (dom)')\n",
    "    if i == 2: plt.legend()\n",
    "    if i == 1: plt.title('Spherical Detector, Reco-True')\n",
    "    plt.xlabel(par_names[i])\n",
    "    \n",
    "#plt.savefig('images/spherical_reco.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
