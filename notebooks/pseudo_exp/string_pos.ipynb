{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dama as dm\n",
    "import pickle\n",
    "import os\n",
    "import awkward as ak\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from freedom.toy_model.toy_model_functions import toy_model\n",
    "from freedom.toy_model.detectors import get_box_detector\n",
    "from types import SimpleNamespace\n",
    "from freedom.toy_model import NNs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'figure.figsize': (7, 7*0.618),\n",
    "          'legend.fontsize': 14,\n",
    "          'axes.labelsize': 16,\n",
    "          'axes.titlesize': 16,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "par_names = ['x', 'y', 'z', 't', r'$\\phi^{azimuth}$', r'$\\theta^{zenith}$',  r'$E^{deposited}$', 'I']\n",
    "\n",
    "def plot_truth(axes, truth, idx=(0,1)):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([truth[idx[0]]], [truth[idx[1]]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, limit_diff=False, **kwargs):\n",
    "    \n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    a.plot_contour(ax=axes[0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[0].set_title(title_a)\n",
    "    b.plot_contour(ax=axes[1], levels=levels,  labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    if limit_diff:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-vmax, vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "    else:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)), \n",
    "                  label=r'$\\Delta LLH$', **kwargs) \n",
    "    axes[2].set_title(title_a + ' - ' + title_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om = np.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model(om)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, meta = toy_experiment.generate_events(n=10_000_000, gamma=0, gen_volume=\"sphere\",\n",
    "                                              e_lim=(1,50), inelast_lim=(0,1), radius=50., t_width=0,\n",
    "                                              contained=False) #, min_hits=3\n",
    "truths = NNs.make_truth_array(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.count(events.photons.t, axis=1).to_numpy(), np.linspace(0,100,101))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - per dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, time_spread=50) #, shuffle='inDOM'\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, time_spread=50) #, shuffle='inDOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel_d = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    hmodel_d.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel_d.fit(d_train, epochs=60, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel_d.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel_d.layers[-1].activation = tf.keras.activations.linear\n",
    "#hmodel_d.compile()\n",
    "\n",
    "#hmodel_d.save('networks/string_toy_hitnet_dom.h5')\n",
    "hmodel_d = tf.keras.models.load_model('networks/string_toy_hitnet_dom.h5',\n",
    "                                     custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_dom_data(events, om)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "with strategy.scope():\n",
    "    dmodel = NNs.get_hmodel(x_shape=4, t_shape=8, trafo=NNs.dom_trafo_3D, activation='swish', final_activation='swish')\n",
    "    dmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dmodel.fit(d_train, epochs=25, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = dmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "#dmodel.compile()\n",
    "\n",
    "#dmodel.save('networks/string_toy_chargenet_dom.h5')\n",
    "dmodel = tf.keras.models.load_model('networks/string_toy_chargenet_dom.h5',\n",
    "                                    custom_objects={'dom_trafo_3D':NNs.dom_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_om(xs, ts):\n",
    "    ts[:, :3] -= xs[:, :3]\n",
    "    xs[:, :3] -= xs[:, :3]\n",
    "    return xs, ts\n",
    "\n",
    "def heart(n, r=5):\n",
    "    x = np.linspace(-1,1,n)\n",
    "    a = np.hstack([x.reshape(-1,1), (np.sqrt(np.abs(x)) + np.sqrt(1-x**2)).reshape(-1,1)])\n",
    "    b = np.hstack([x.reshape(-1,1), (np.sqrt(np.abs(x)) - np.sqrt(1-x**2)).reshape(-1,1)])\n",
    "    return r*np.append(a, b, axis=0)\n",
    "\n",
    "def cube(d, n=5, return_dens=False):\n",
    "    x = np.linspace(0, d*(n-1), n) - 0.5*d*(n-1)\n",
    "    a, b, c = np.meshgrid(x, x, x)\n",
    "    out = np.zeros((n**3, 3))\n",
    "    out[:, 0] = a.flatten()\n",
    "    out[:, 1] = b.flatten()\n",
    "    out[:, 2] = c.flatten()\n",
    "    if return_dens:\n",
    "        return out, n**3/(d*(n-1))**3\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_pos = np.array([[0,0], [5,5], [6,2.5], [7.5,0], [-2,2.5], [-2,5]]) #heart(20) #\n",
    "#z_pos = np.linspace(-10,10,6) #np.linspace(-10,10,3) #\n",
    "\n",
    "#detector = np.append(np.repeat(str_pos, len(z_pos), axis=0), np.tile(z_pos, len(str_pos)).reshape(-1,1), axis=1)\n",
    "detector = cube(10, 5)\n",
    "toy_experiment = toy_model(detector)\n",
    "\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(detector[:,0], detector[:,1], detector[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([2., 0., 5., 0, 3, np.arccos(0), 2., 0.3])\n",
    "\n",
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(truth)\n",
    "print(np.sum(test_event[1]))\n",
    "\n",
    "segments = toy_experiment.model(*truth)\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_box_aspect([1,1,1])\n",
    "ax.scatter(detector[:,0],detector[:,1],detector[:,2],s=10, c='black', marker='x', alpha=0.5)\n",
    "ax.scatter(segments[:,0],segments[:,1],segments[:,2],s=segments[:,4]/100, c=segments[:,3])\n",
    "ax.scatter(test_event[0][:, 0], test_event[0][:, 1], test_event[0][:, 2],\n",
    "           s=30, c=np.log(test_event[0][:,3]), cmap='turbo')\n",
    "#ax.view_init(45, 45)\n",
    "\n",
    "#plt.savefig('images/string_pos/test_event_det4.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid scan\n",
    "\n",
    "g = dm.GridData(x=np.linspace(-7, 7, 100), y=np.linspace(-7, 7, 100))\n",
    "#g = dm.GridData(x=np.linspace(1, 50, 100), y=np.linspace(0, 1, 100))\n",
    "IDX = (0,1)\n",
    "\n",
    "g['dom_hit_term'] = np.empty(g.shape)\n",
    "g['dom_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g.shape):\n",
    "    p[IDX[0]] = g['x'][idx]\n",
    "    p[IDX[1]] = g['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    \n",
    "g['dom_hit_term'] -= g['dom_hit_term'].min()\n",
    "g['dom_charge_terms'] -= g['dom_charge_terms'].min()\n",
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['dom_llh'] -= g['dom_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "#xxs, tts = shift_om(xxs, tts)\n",
    "\n",
    "llhs = -hmodel_d.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_dom = llhs.reshape(g.shape)\n",
    "g.hit_llh_dom -= g.hit_llh_dom.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, IDX[0]] = g.get_array('x', flat=True)\n",
    "tts[:, IDX[1]] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "#xxs, tts = shift_om(xxs, tts)\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g.charge_llh_dom = llhs.reshape(g.shape)\n",
    "g.charge_llh_dom -= g.charge_llh_dom.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.dom_hit_term, \n",
    "          g.hit_llh_dom, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, \n",
    "          g.charge_llh_dom, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "ana, NN = g.dom_hit_term+g.dom_charge_terms, g.hit_llh_dom+g.charge_llh_dom\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth, IDX)\n",
    "\n",
    "#plt.savefig('images/string_pos/test_llh_det4.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical_opt import spherical_opt\n",
    "from multiprocessing import Pool, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_points(hits, n_live_points, bound=bounds, seed=[None]):\n",
    "    if seed[0] == None:\n",
    "        avg = np.average(hits[:, :3], axis=0)\n",
    "        low_lims = np.concatenate([avg-np.array([3,3,3]), np.array([-50,0,0,1,0])])\n",
    "        hig_lims = np.concatenate([avg+np.array([3,3,3]), np.array([50,2*np.pi,np.pi,30,1])])\n",
    "    else:\n",
    "        low_lims = seed - np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "        hig_lims = seed + np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "    \n",
    "    uniforms = np.random.uniform(size=(n_live_points, 8))\n",
    "    initial_points = low_lims + uniforms * (hig_lims - low_lims)\n",
    "    initial_points = np.clip(initial_points, bounds[:, 0], bounds[:, 1])\n",
    "    return initial_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_pos = np.array([[0,0], [2,0], [4,0], [-2,0], [-4,0]])\n",
    "#z_pos = np.linspace(-10,10,6)\n",
    "\n",
    "#detector = np.append(np.repeat(str_pos, len(z_pos), axis=0), np.tile(z_pos, len(str_pos)).reshape(-1,1), axis=1)\n",
    "detector = cube(2.5, 5) #20-2.5?\n",
    "toy_experiment = toy_model(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 5\n",
    "events, meta = toy_experiment.generate_events(n=5000, gamma=0, gen_volume=\"box\", e_lim=(1,10), inelast_lim=(0,1),\n",
    "                                              x_lim=(-lim,lim), y_lim=(-lim,lim), z_lim=(-lim,lim), t_width=0,\n",
    "                                              contained=False, min_hits=4)\n",
    "truths = NNs.make_truth_array(events)\n",
    "\n",
    "bounds = np.array([[-lim-2,lim+2], [-lim-2,lim+2], [-lim-2,lim+2], [-300,300], [0,2*np.pi], [0,np.pi], [1,30], [0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ak.count(events.photons.t, axis=1).to_numpy()\n",
    "plt.hist(ps, np.linspace(0,np.quantile(ps, 0.99),101))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLH_ana(X, hits, n_obs, form='total', fix=[None], bounds=bounds):\n",
    "    if fix[0] != None:\n",
    "        X = np.insert(X, fix[0], fix[1])\n",
    "\n",
    "    if ~np.alltrue(np.logical_and(bounds[:,0] <= X, X <= bounds[:,1]), axis=-1):\n",
    "        return 1e9\n",
    "    \n",
    "    segments = toy_experiment.model(*X)\n",
    "    if form == 'dom':\n",
    "        h_term = toy_experiment.nllh_p_term_dom(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_dom(segments, n_obs)\n",
    "    elif form == 'total':\n",
    "        h_term = toy_experiment.nllh_p_term_tot(segments, hits)\n",
    "        c_term = toy_experiment.nllh_N_term_tot(segments, n_obs)\n",
    "    else:\n",
    "        raise NameError(\"Formulation must be one of ['total', 'dom'], not \"+form)\n",
    "    \n",
    "    return c_term + h_term\n",
    "\n",
    "def fit_event_ana(event):\n",
    "    hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'sensor_id']], axis=1)\n",
    "    n_obs = event.n_obs.to_numpy() \n",
    "    #truth = event?\n",
    "    \n",
    "    def eval_LLH(params):\n",
    "        if params.ndim == 1:\n",
    "            return LLH_ana(params, hits, n_obs)\n",
    "        else:\n",
    "            llhs = []\n",
    "            for p in params:\n",
    "                llhs.append(LLH_ana(p, hits, n_obs))\n",
    "            return np.array(llhs)\n",
    "\n",
    "    # seeding\n",
    "    initial_points = init_points(hits, 97) #, seed=truth\n",
    "    \n",
    "    # free fit\n",
    "    fit_res = spherical_opt.spherical_opt(\n",
    "        func=eval_LLH,\n",
    "        method=\"CRS2\",\n",
    "        initial_points=initial_points,\n",
    "        rand=np.random.default_rng(42),\n",
    "        spherical_indices=[[4,5]],\n",
    "        batch_size=12,\n",
    "    )\n",
    "\n",
    "    return list(fit_res['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(10) as p:\n",
    "    outs = p.map(fit_event_ana, events)\n",
    "recos_ana = np.array(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = recos_ana - truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "from freedom.llh_service.llh_service import LLHService\n",
    "from freedom.llh_service.llh_client import LLHClient\n",
    "from freedom.reco import crs_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'networks/'\n",
    "service_conf = {\n",
    "        \"poll_timeout\": 1,\n",
    "        \"flush_period\": 1,\n",
    "        \"n_hypo_params\": 8,\n",
    "        \"n_hit_features\": 6,\n",
    "        \"n_evt_features\": len(detector)*4,\n",
    "        \"batch_size\" : {\n",
    "          \"n_hypos\": 200,\n",
    "          \"n_observations\": 6000, \n",
    "        },\n",
    "        \"send_hwm\": 10000,\n",
    "        \"recv_hwm\": 10000,\n",
    "        \"hitnet_file\": loc+'string_toy_hitnet_dom.h5',\n",
    "        \"domnet_file\": loc+'string_toy_chargenet_dom.h5',\n",
    "        \"ndoms\": len(detector),\n",
    "        \"toy\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 4\n",
    "\n",
    "base_req = \"ipc:///tmp/recotestreq\"\n",
    "base_ctrl = \"ipc:///tmp/recotestctrl\"\n",
    "\n",
    "req_addrs = []\n",
    "ctrl_addrs = []\n",
    "for i in range(n_gpus):\n",
    "    req_addrs.append(f'{base_req}{i}')\n",
    "    ctrl_addrs.append(f'{base_ctrl}{i}')\n",
    "    \n",
    "procs = []\n",
    "for i in range(n_gpus):\n",
    "    proc = Process(target=crs_reco.start_service, args=(service_conf, ctrl_addrs[i], req_addrs[i], i))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_events_nn(events, index, Truths, ctrl_addrs):\n",
    "    outputs = []\n",
    "\n",
    "    client = LLHClient(ctrl_addr=ctrl_addrs[index], conf_timeout=60000)\n",
    "    def Eval_llh(params, hits, n_obs, fix=[None]):\n",
    "        if fix[0] != None:\n",
    "            params = np.insert(params, fix[0], fix[1])\n",
    "            \n",
    "        if ~np.alltrue(np.logical_and(bounds[:,0] <= params, params <= bounds[:,1]), axis=-1):\n",
    "            return 1e9\n",
    "\n",
    "        c_data = np.hstack([detector, n_obs[:, np.newaxis]])\n",
    "        return client.eval_llh(hits, c_data, params)\n",
    "\n",
    "    for j, event in enumerate(events):\n",
    "        hits = np.stack([event.photons[var].to_numpy() for var in ['x', 'y', 'z', 't', 'q', 'sensor_id']], axis=1)\n",
    "        n_obs = event.n_obs.to_numpy()\n",
    "        \n",
    "        def eval_LLH(params):\n",
    "            if params.ndim == 1:\n",
    "                return Eval_llh(params, hits, n_obs)\n",
    "            else:\n",
    "                o = []\n",
    "                for p in params:\n",
    "                    o.append(Eval_llh(p, hits, n_obs))\n",
    "                return np.array(o)\n",
    "\n",
    "        # seeding\n",
    "        initial_points = init_points(hits, 97) #, seed=Truths[j]\n",
    "        \n",
    "        #free fit\n",
    "        fit_res = spherical_opt.spherical_opt(\n",
    "            func=eval_LLH,\n",
    "            method=\"CRS2\",\n",
    "            initial_points=initial_points,\n",
    "            rand=np.random.default_rng(42),\n",
    "            spherical_indices=[[4,5]],\n",
    "            batch_size=12,\n",
    "        )\n",
    "        outputs.append(fit_res['x'])\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = len(events)\n",
    "pool_size = 200\n",
    "evts_per_proc = int(math.ceil(events_to_process/pool_size))\n",
    "evt_splits = [events[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)] #_red\n",
    "true_splits = [truths[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "print(sum(len(l) for l in evt_splits))\n",
    "\n",
    "gpu_inds = np.arange(pool_size) % n_gpus\n",
    "\n",
    "fit_events_partial = partial(\n",
    "        fit_events_nn,\n",
    "        ctrl_addrs=ctrl_addrs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reconstruct with a worker pool; one LLH client per worker\n",
    "with Pool(pool_size) as p:\n",
    "    outs = p.starmap(fit_events_partial, zip(evt_splits, gpu_inds, true_splits))\n",
    "\n",
    "all_outs = sum((out for out in outs), [])\n",
    "all_outs = np.array(all_outs).reshape((events_to_process, 8))\n",
    "recos_nn = np.array(all_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_nn = recos_nn - truths\n",
    "diff_nn[:, -2] = np.log10(recos_nn[:, -2] / truths[:, -2])\n",
    "#np.save('recos/string/diff_nn_cub_10_5_sameGen', diff_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all the services\n",
    "import zmq\n",
    "for proc, ctrl_addr in zip(procs, ctrl_addrs): \n",
    "    with zmq.Context.instance().socket(zmq.REQ) as ctrl_sock:\n",
    "        ctrl_sock.connect(ctrl_addr)\n",
    "        ctrl_sock.send_string(\"die\")\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_iqr(x, n=100, f=0.2):\n",
    "    iqrs = np.zeros((n,8))\n",
    "    for i in range(n):\n",
    "        #inds = np.random.choice(range(len(x)), size=int(f*len(x)), replace=False)\n",
    "        inds = np.random.choice(range(len(x)), size=len(x))\n",
    "        iqrs[i] = stats.iqr(x[inds], axis=0)\n",
    "    return np.mean(iqrs, axis=0), np.std(iqrs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, diffs, uncs = ['2p5','3','3p5','4p2','5','6','7','8p4','10','12','14','17','20'], [], []\n",
    "\n",
    "for p in points:\n",
    "    exec(\"diff_nn_cub_%s_5 = np.load('recos/string/diff_nn_cub_%s_5.npy')\"%(p,p))\n",
    "    #exec(\"diffs.append(stats.iqr(diff_nn_cub_%s_5, axis=0))\"%(p))\n",
    "    exec(\"d, u = bootstrap_iqr(diff_nn_cub_%s_5)\"%(p))\n",
    "    exec(\"diffs.append(d)\")\n",
    "    exec(\"uncs.append(u)\")\n",
    "\n",
    "diffs = np.vstack(diffs).T\n",
    "uncs = np.vstack(uncs).T\n",
    "\n",
    "xs, dens = np.logspace(np.log10(2.5), np.log10(20), 13), []\n",
    "for x in xs:\n",
    "    dens.append(cube(x, 5, True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['tab:blue','tab:blue','tab:blue','tab:orange','tab:green','tab:green','tab:red','tab:purple']\n",
    "pos = [[2.5e-4,0.16], [3.2e-4,0.16], [2e-3,0.13], [3e-4,0.05], [2e-4,0.21], [2e-4,0.43], [1.9e-4,0.59], [3e-4,0.73]]\n",
    "styles = ['-.','--',':','-','--',':','-','-',]\n",
    "par_names = ['x', 'y', 'z', 't', r'$\\phi^{azimuth}$', r'$\\theta^{zenith}$',  r'$E^{deposited}$', 'I']\n",
    "#par_names = ['x', 'y', 'z', 't', r'$\\varphi$', r'$\\vartheta$',  r'E', 'I']\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7*0.618))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "for i in range(8):\n",
    "    ax1.fill_between(dens, np.min(diffs[i])/(diffs[i]-uncs[i]), np.min(diffs[i])/(diffs[i]+uncs[i]), \n",
    "                     color=colors[i], alpha=0.2)\n",
    "    ax1.plot(dens, np.min(diffs[i])/diffs[i], label=par_names[i], color=colors[i], linestyle=styles[i])\n",
    "#ax1.legend()\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Sensor density')\n",
    "ax1.set_ylabel('Parameter resolution (IQR) \\n normalized to best value   ')\n",
    "ax1.set_ylim(0,1.05)\n",
    "\n",
    "for i in range(8):\n",
    "    ax1.text(pos[i][0], pos[i][1], par_names[i], size=16, color=colors[i])\n",
    "\n",
    "ax2.set_xlabel('Detector volume')\n",
    "ax2.plot(125/np.array(dens), 2*np.ones(len(dens)))\n",
    "ax2.set_xscale('log')\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "#plt.savefig('images/string_pos/res_vs_dens.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_nn_cub_20_5_sameGen = np.load('recos/string/diff_nn_cub_20_5_sameGen.npy')\n",
    "diff_nn_cub_5_5_sameGen = np.load('recos/string/diff_nn_cub_5_5_sameGen.npy')\n",
    "\n",
    "print(stats.iqr(diff_nn_cub_20_5_sameGen, axis=0) / stats.iqr(diff_nn_cub_20_5, axis=0))\n",
    "print('---------------------------')\n",
    "print(stats.iqr(diff_nn_cub_5_5_sameGen, axis=0) / stats.iqr(diff_nn_cub_5_5, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
