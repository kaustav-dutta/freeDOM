{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dama as dm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from freedom.toy_model.toy_model_functions import toy_model\n",
    "from freedom.toy_model.detectors import get_box_detector\n",
    "from types import SimpleNamespace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14 \n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = np.load('../../freedom/resources/geo_array_upgrade.npy')\n",
    "str_pos = geo[:, 42][:, :2]\n",
    "z_pos = np.linspace(-200, -500, 20) #80\n",
    "\n",
    "detector = np.append(np.repeat(str_pos, len(z_pos), axis=0), np.tile(z_pos, len(str_pos)).reshape(-1,1), axis=1)\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "#ax.scatter(detector[:,0], detector[:,1], detector[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_experiment = toy_model(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([50., -50., -250., 0, 0, np.arccos(0), 20., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one test event\n",
    "test_event = toy_experiment.generate_event(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid scan\n",
    "\n",
    "g = dm.GridData(x=np.linspace(0, 100, 100), y=np.linspace(-100, 0, 100))\n",
    "\n",
    "g['dom_hit_term'] = np.empty(g.shape)\n",
    "g['dom_charge_terms'] = np.empty(g.shape)\n",
    "g['total_charge_hit_terms'] = np.empty(g.shape)\n",
    "g['total_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g.shape):\n",
    "    p[0] = g['x'][idx]\n",
    "    p[1] = g['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    g['total_charge_hit_terms'][idx] = toy_experiment.nllh_p_term_tot(segments, test_event[0])\n",
    "    g['total_charge_terms'][idx] = toy_experiment.nllh_N_term_tot(segments, test_event[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['dom_hit_term'] -= g['dom_hit_term'].min()\n",
    "g['dom_charge_terms'] -= g['dom_charge_terms'].min()\n",
    "g['dom_llh'] = g['dom_hit_term'] + g['dom_charge_terms']\n",
    "g['total_charge_hit_terms'] -= g['total_charge_hit_terms'].min()\n",
    "g['total_charge_terms'] -= g['total_charge_terms'].min()\n",
    "g['total_charge_llh'] = g['total_charge_hit_terms'] + g['total_charge_terms']\n",
    "g['dom_llh'] -= g['dom_llh'].min()\n",
    "g['total_charge_llh'] -= g['total_charge_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_truth(axes, truth):\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    for ax in axes.flatten():\n",
    "        ax.plot([truth[0]], [truth[1]], marker='$T$', markersize=10, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(a, b, axes, title_a='a', title_b='b', vmax=None, limit_diff=False, **kwargs):\n",
    "    \n",
    "    levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "    labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "    #a.plot(ax=axes[0], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    a.plot_contour(ax=axes[0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[0].set_title(title_a)\n",
    "    #b.plot(ax=axes[1], cmap='Greys', label=r'$\\Delta LLH$', **kwargs)\n",
    "    b.plot_contour(ax=axes[1], levels=levels,  labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[1].set_title(title_b)\n",
    "    diff = a - b\n",
    "    if limit_diff:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-vmax, vmax=vmax, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "        #np.clip(-diff, 0, None).plot_contour(ax=axes[2], levels=[0.1,0.2, 0.3], colors=['r']*2)\n",
    "    else:\n",
    "        diff.plot(ax=axes[2], cmap='RdBu', cbar=True, vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)), label=r'$\\Delta LLH$', **kwargs) \n",
    "        #diff.plot_contour(ax=axes[2], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$', **kwargs)\n",
    "    axes[2].set_title(title_a + ' - ' + title_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats.norm.isf(stats.chi2(df=2).sf(g['dom_llh']*2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "plot_diff(g['dom_hit_term'], g['total_charge_hit_terms'], axes=ax[0], title_a='per DOM hit', title_b='total hit', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_charge_terms'], g['total_charge_terms'], axes=ax[1], title_a='per DOM charge', title_b='total charge', vmax=20, limit_diff=True)\n",
    "plot_diff(g['dom_llh'], g['total_charge_llh'], axes=ax[2], title_a='per DOM llh', title_b='total llh', limit_diff=False)\n",
    "\n",
    "plot_truth(ax, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freedom.toy_model import NNs\n",
    "%aimport freedom.toy_model.NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, truths = toy_experiment.generate_event_box(n=100_000, x_lim=(4,100), y_lim=(-94,-21), z_lim=(-510,-210),\n",
    "                                                   e_lim=(5,60), t_width=0, contained=False, N_min=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "nGPUs = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hit Net - per dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_hit_data(events, truths)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=150)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs, shuffle='inDOM', time_spread=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2e-5)\n",
    "\n",
    "with strategy.scope():\n",
    "    hmodel = NNs.get_hmodel(x_shape=6, t_shape=8, trafo=NNs.hit_trafo_3D, activation='swish', final_activation='swish')\n",
    "    hmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = hmodel.fit(d_train, epochs=15, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = hmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g.hit_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.hit_llh_dom -= g.hit_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_hit_term, g.hit_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmodel.save('networks/upgrade_toy_hitnet_dom.h5')\n",
    "#hmodel = tf.keras.models.load_model('networks/upgrade_toy_hitnet_dom.h5',\n",
    "#                                     custom_objects={'hit_trafo_3D':NNs.hit_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge Net - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_0s(x, t, n=1):\n",
    "    keep = np.where(x[:,-1]>0)[0]\n",
    "    keep = np.append(keep, np.random.choice(np.where(x[:,-1]==0)[0], n*len(keep)))\n",
    "    return x[keep], t[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = NNs.get_dom_data(events, truths, detector)\n",
    "#x, t = remove_0s(x, t)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.1, random_state=42)\n",
    "\n",
    "d_train = NNs.DataGenerator(x_train, t_train, batch_size=4096*nGPUs)\n",
    "d_valid = NNs.DataGenerator(x_test, t_test, batch_size=4096*nGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "\n",
    "with strategy.scope():\n",
    "    dmodel = NNs.get_hmodel(x_shape=4, t_shape=8, trafo=NNs.dom_trafo_3D, activation='swish', final_activation='swish')\n",
    "    dmodel.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = dmodel.fit(d_train, epochs=10, verbose=1, validation_data=d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab = d_valid.__getitem__(0)\n",
    "pred = dmodel.predict(inp, batch_size=4096).flatten()\n",
    "plt.hist(pred[lab==0], 100, histtype='step')\n",
    "plt.hist(pred[lab==1], 100, histtype='step');\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g.shape), axis=0)\n",
    "tts[:, 0] = g.get_array('x', flat=True)\n",
    "tts[:, 1] = g.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "dmodel.compile()\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g.charge_llh_dom = llhs.reshape(g.shape)\n",
    "\n",
    "g.charge_llh_dom -= g.charge_llh_dom.min()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, g.charge_llh_dom, title_a='Analytic', title_b='NN', vmax=10, axes=ax, limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "#plt.savefig('images/hitNNtest.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmodel.save('networks/upgrade_toy_chargenet_dom.h5')\n",
    "#dmodel = tf.keras.models.load_model('networks/upgrade_toy_chargenet_dom.h5',\n",
    "#                                     custom_objects={'dom_trafo_3D':NNs.dom_trafo_3D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLH - per DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(20,17))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "plot_diff(g.dom_hit_term, \n",
    "          g.hit_llh_dom, \n",
    "          title_a='Hit Analytic', title_b='Hit NN', vmax=10, axes=ax[0], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "plot_diff(g.dom_charge_terms, \n",
    "          g.charge_llh_dom, \n",
    "          title_a='Charge Analytic', title_b='Charge NN', vmax=10, axes=ax[1], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "ana, NN = g.dom_hit_term+g.dom_charge_terms, g.hit_llh_dom+g.charge_llh_dom\n",
    "plot_diff(ana-ana.min(), \n",
    "          NN-NN.min(), \n",
    "          title_a='Analytic', title_b='NN', vmax=10, axes=ax[2], limit_diff=True)\n",
    "plot_truth(ax, truth)\n",
    "\n",
    "#plt.savefig('images/NNtest_perDOM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "g2 = dm.GridData(x=np.linspace(5, 50, 100), y=np.linspace(5, 50, 100))\n",
    "\n",
    "g2['dom_hit_term'] = np.empty(g.shape)\n",
    "g2['dom_charge_terms'] = np.empty(g.shape)\n",
    "\n",
    "p = np.copy(truth)\n",
    "\n",
    "for idx in np.ndindex(g2.shape):\n",
    "    p[6] = g2['x'][idx]\n",
    "    p[7] = g2['y'][idx]\n",
    "    segments = toy_experiment.model(*p)\n",
    "    g2['dom_hit_term'][idx] = toy_experiment.nllh_p_term_dom(segments, test_event[0])\n",
    "    g2['dom_charge_terms'][idx] = toy_experiment.nllh_N_term_dom(segments, test_event[1])\n",
    "    \n",
    "g2['dom_hit_term'] -= g2['dom_hit_term'].min()\n",
    "g2['dom_charge_terms'] -= g2['dom_charge_terms'].min()\n",
    "g2['dom_llh'] = g2['dom_hit_term'] + g2['dom_charge_terms']\n",
    "g2['dom_llh'] -= g2['dom_llh'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxs = np.repeat(test_event[0][np.newaxis, :], np.prod(g2.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 6)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g2.shape), axis=0)\n",
    "tts[:, 6] = g2.get_array('x', flat=True)\n",
    "tts[:, 7] = g2.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(test_event[0]), axis=0)\n",
    "\n",
    "hmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "hmodel.compile()\n",
    "\n",
    "llhs = -hmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(test_event[0]))), axis=1)\n",
    "\n",
    "g2.hit_llh_dom = llhs.reshape(g2.shape)\n",
    "g2.hit_llh_dom -= g2.hit_llh_dom.min()\n",
    "\n",
    "\n",
    "xx = []\n",
    "ind = test_event[0][:, 5]\n",
    "for i in range(len(detector)):\n",
    "    d = np.append(detector[i], np.sum(ind==i))\n",
    "    xx.append(list(d))\n",
    "xxs = np.repeat(np.array(xx)[np.newaxis, :], np.prod(g2.shape), axis=0)\n",
    "xxs = xxs.reshape(-1, 4)\n",
    "\n",
    "tts = np.repeat(truth[np.newaxis, :], np.prod(g2.shape), axis=0)\n",
    "tts[:, 6] = g2.get_array('x', flat=True)\n",
    "tts[:, 7] = g2.get_array('y', flat=True)\n",
    "tts = np.repeat(tts, len(detector), axis=0)\n",
    "\n",
    "dmodel.layers[-1].activation = tf.keras.activations.linear\n",
    "dmodel.compile()\n",
    "\n",
    "llhs = -dmodel.predict((xxs, tts), batch_size=4096)\n",
    "llhs = np.sum(np.nan_to_num(llhs.reshape(-1, len(detector))), axis=1)\n",
    "\n",
    "g2.charge_llh_dom = llhs.reshape(g2.shape)\n",
    "g2.charge_llh_dom -= g2.charge_llh_dom.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = stats.chi2(df=2).isf(stats.norm.sf(np.arange(1,6))*2)/2    \n",
    "labels = [str(i) + r'$\\sigma$' for i in range(1,6)]\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.9, 6))\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,9))\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "\n",
    "g2.dom_hit_term.plot_contour(ax=ax[0][0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$')\n",
    "ax[0][0].plot([truth[6]], [truth[7]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "g2.hit_llh_dom.plot_contour(ax=ax[0][1], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$')\n",
    "ax[0][1].plot([truth[6]], [truth[7]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "g2.dom_charge_terms.plot_contour(ax=ax[1][0], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$')\n",
    "ax[1][0].plot([truth[6]], [truth[7]], marker='$T$', markersize=10, color='k')\n",
    "\n",
    "g2.charge_llh_dom.plot_contour(ax=ax[1][1], levels=levels, labels=labels, colors=colors, label=r'$\\Delta LLH$')\n",
    "ax[1][1].plot([truth[6]], [truth[7]], marker='$T$', markersize=10, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical_opt import spherical_opt\n",
    "from multiprocessing import Pool, Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[14,90], [-84,-31], [-500,-200], [-700,700], [0,2*np.pi], [0,np.pi], [5,50], [5,50]])\n",
    "\n",
    "def init_points(hits, n_live_points, bound=bounds, seed=[None]):\n",
    "    if seed[0] == None:\n",
    "        avg = np.average(hits[:, :4], axis=0)\n",
    "        low_lims = np.concatenate([avg-np.array([10,10,30,200]), np.array([0,0,5,5])])\n",
    "        hig_lims = np.concatenate([avg+np.array([10,10,30,0]), np.array([2*np.pi,np.pi,50,50])])\n",
    "    else:\n",
    "        low_lims = seed - np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "        hig_lims = seed + np.array([1, 1, 1, 5, 0.5, 0.3, 3, 3])\n",
    "    \n",
    "    uniforms = np.random.uniform(size=(n_live_points, 8))\n",
    "    initial_points = low_lims + uniforms * (hig_lims - low_lims)\n",
    "    initial_points = np.clip(initial_points, bounds[:, 0], bounds[:, 1])\n",
    "    return initial_points\n",
    "\n",
    "def remove_strings(events, str_num, om_per_string=80):\n",
    "    if isinstance(str_num, int):\n",
    "        str_num = [str_num]\n",
    "        \n",
    "    remove_indx = []\n",
    "    for s in str_num:\n",
    "        remove_indx.extend(np.arange(om_per_string)+s*om_per_string)\n",
    "        \n",
    "    events_out = []\n",
    "    for e in events:\n",
    "        h, c = np.array(e[0]), np.array(e[1])\n",
    "        if np.sum(c) == 0:\n",
    "            events_out.append((h,c))\n",
    "            continue\n",
    "\n",
    "        h = h[[item not in remove_indx for item in h[:,-1]]]\n",
    "        c = np.delete(c, remove_indx)\n",
    "        events_out.append((h,c))\n",
    "    \n",
    "    return np.array(events_out), remove_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, truths = toy_experiment.generate_event_box(n=1000, x_lim=(14,90), y_lim=(-84,-31), z_lim=(-500,-200),\n",
    "                                                   e_lim=(5,50), t_width=0, contained=False, N_min=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_red, remove_indx = remove_strings(events, [0,2])\n",
    "toy_experiment_red = toy_model(np.delete(detector, remove_indx, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLH_ana(X, event, form='dom', fix=[None], bounds=bounds, toy_experiment=toy_experiment):\n",
    "    if fix[0] != None:\n",
    "        X = np.insert(X, fix[0], fix[1])\n",
    "        \n",
    "    if ~np.alltrue(np.logical_and(bounds[:,0] <= X, X <= bounds[:,1]), axis=-1):\n",
    "        return 1e9\n",
    "    \n",
    "    segments = toy_experiment.model(*X)\n",
    "    if form == 'dom':\n",
    "        h_term = toy_experiment.nllh_p_term_dom(segments, event[0])\n",
    "        c_term = toy_experiment.nllh_N_term_dom(segments, event[1])\n",
    "    elif form == 'total':\n",
    "        h_term = toy_experiment.nllh_p_term_tot(segments, event[0])\n",
    "        c_term = toy_experiment.nllh_N_term_tot(segments, event[1])\n",
    "    else:\n",
    "        raise NameError(\"Formulation must be one of ['total', 'dom'], not \"+form)\n",
    "    \n",
    "    return c_term + h_term\n",
    "\n",
    "def fit_event_ana(event):\n",
    "    event, truth = event\n",
    "    \n",
    "    def eval_LLH(params):\n",
    "        if params.ndim == 1:\n",
    "            return LLH_ana(params, event, toy_experiment=toy_experiment)\n",
    "        else:\n",
    "            llhs = []\n",
    "            for p in params:\n",
    "                llhs.append(LLH_ana(p, event, toy_experiment=toy_experiment))\n",
    "            return np.array(llhs)\n",
    "\n",
    "    # seeding\n",
    "    initial_points = init_points(event[0], 97) #, seed=truth\n",
    "    \n",
    "    # free fit\n",
    "    fit_res = spherical_opt.spherical_opt(\n",
    "        func=eval_LLH,\n",
    "        method=\"CRS2\",\n",
    "        initial_points=initial_points,\n",
    "        rand=np.random.default_rng(42),\n",
    "        spherical_indices=[[4,5]],\n",
    "        batch_size=12,\n",
    "    )\n",
    "\n",
    "    return list(fit_res['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(10) as p:\n",
    "    outs = p.map(fit_event_ana, zip(events, truths))\n",
    "recos_ana = np.array(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ana = recos_ana - truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "from freedom.llh_service.llh_service import LLHService\n",
    "from freedom.llh_service.llh_client import LLHClient\n",
    "from freedom.reco import crs_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'networks/'\n",
    "service_conf = {\n",
    "        \"poll_timeout\": 1,\n",
    "        \"flush_period\": 1,\n",
    "        \"n_hypo_params\": 8,\n",
    "        \"n_hit_features\": 6,\n",
    "        \"n_evt_features\": len(detector)*4,\n",
    "        \"batch_size\" : {\n",
    "          \"n_hypos\": 200,\n",
    "          \"n_observations\": 6000, \n",
    "        },\n",
    "        \"send_hwm\": 10000,\n",
    "        \"recv_hwm\": 10000,\n",
    "        \"hitnet_file\": loc+'upgrade_toy_hitnet_dom.h5',\n",
    "        \"domnet_file\": loc+'upgrade_toy_chargenet_dom.h5',\n",
    "        \"ndoms\": len(detector),\n",
    "        \"toy\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 4\n",
    "\n",
    "base_req = \"ipc:///tmp/recotestreq\"\n",
    "base_ctrl = \"ipc:///tmp/recotestctrl\"\n",
    "\n",
    "req_addrs = []\n",
    "ctrl_addrs = []\n",
    "for i in range(n_gpus):\n",
    "    req_addrs.append(f'{base_req}{i}')\n",
    "    ctrl_addrs.append(f'{base_ctrl}{i}')\n",
    "    \n",
    "procs = []\n",
    "for i in range(n_gpus):\n",
    "    proc = Process(target=crs_reco.start_service, args=(service_conf, ctrl_addrs[i], req_addrs[i], i))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_events_nn(events, index, Truths, ctrl_addrs):\n",
    "    outputs = []\n",
    "\n",
    "    client = LLHClient(ctrl_addr=ctrl_addrs[index], conf_timeout=60000)\n",
    "    def Eval_llh(params, event, fix=[None]):\n",
    "        if fix[0] != None:\n",
    "            params = np.insert(params, fix[0], fix[1])\n",
    "            \n",
    "        if ~np.alltrue(np.logical_and(bounds[:,0] <= params, params <= bounds[:,1]), axis=-1):\n",
    "            return 1e9\n",
    "        \n",
    "        #event_red, remove_indx = remove_strings(event, [0,2])\n",
    "        #c_data, _ = NNs.get_dom_data(np.array([event_red]), np.ones((1,8)), np.delete(detector, remove_indx, axis=0))\n",
    "        c_data, _ = NNs.get_dom_data(np.array([event]), np.ones((1,8)), detector)\n",
    "        return client.eval_llh(event[0], c_data, params)\n",
    "\n",
    "    for j, event in enumerate(events):\n",
    "        def eval_LLH(params):\n",
    "            if params.ndim == 1:\n",
    "                return Eval_llh(params, event)\n",
    "            else:\n",
    "                o = []\n",
    "                for p in params:\n",
    "                    o.append(Eval_llh(p, event))\n",
    "                return np.array(o)\n",
    "\n",
    "        # seeding\n",
    "        initial_points = init_points(event[0], 97) #, seed=Truths[j]\n",
    "        \n",
    "        #free fit\n",
    "        fit_res = spherical_opt.spherical_opt(\n",
    "            func=eval_LLH,\n",
    "            method=\"CRS2\",\n",
    "            initial_points=initial_points,\n",
    "            rand=np.random.default_rng(42),\n",
    "            spherical_indices=[[4,5]],\n",
    "            batch_size=12,\n",
    "        )\n",
    "        outputs.append(fit_res['x'])\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = len(events)\n",
    "pool_size = 200\n",
    "evts_per_proc = int(math.ceil(events_to_process/pool_size))\n",
    "evt_splits = [events[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)] #_red\n",
    "true_splits = [truths[i*evts_per_proc:(i+1)*evts_per_proc] for i in range(pool_size)]\n",
    "print(sum(len(l) for l in evt_splits))\n",
    "\n",
    "gpu_inds = np.arange(pool_size) % n_gpus\n",
    "\n",
    "fit_events_partial = partial(\n",
    "        fit_events_nn,\n",
    "        ctrl_addrs=ctrl_addrs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reconstruct with a worker pool; one LLH client per worker\n",
    "with Pool(pool_size) as p:\n",
    "    outs = p.starmap(fit_events_partial, zip(evt_splits, gpu_inds, true_splits))\n",
    "\n",
    "all_outs = sum((out for out in outs), [])\n",
    "all_outs = np.array(all_outs).reshape((events_to_process, 8))\n",
    "recos_nn = np.array(all_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_nn = recos_nn - truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all the services\n",
    "import zmq\n",
    "for proc, ctrl_addr in zip(procs, ctrl_addrs): \n",
    "    with zmq.Context.instance().socket(zmq.REQ) as ctrl_sock:\n",
    "        ctrl_sock.connect(ctrl_addr)\n",
    "        ctrl_sock.send_string(\"die\")\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_names = ['x', 'y', 'z', 't', 'azi', 'zen', 'Ecscd', 'Etrck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 17))\n",
    "\n",
    "for i in range(8):\n",
    "    r = min(bounds[i][1] - bounds[i][0], 200)\n",
    "    bins = np.linspace(-r/2, r/2, 50)\n",
    "    \n",
    "    plt.subplot(3,3,i+1)\n",
    "    #plt.hist(diff_ana[:, i], bins, alpha=0.5, label='Analytic')\n",
    "    #plt.hist(diff_ana_red[:, i], bins, alpha=0.5, label='Analytic reduced')\n",
    "    #plt.hist(diff_nn[:, i], bins, alpha=0.5, label='NN')\n",
    "    #plt.hist(diff_nn_red[:, i], bins, alpha=0.5, label='NN reduced')\n",
    "    #plt.hist(recos_ana[:, i], 50, alpha=0.5, label='Analytic')\n",
    "    plt.hist(recos_nn[:, i], 50, alpha=0.5, label='NN')\n",
    "    if i == 2: plt.legend()\n",
    "    plt.xlabel(par_names[i])\n",
    "    \n",
    "#plt.savefig('images/upgrade_reco.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(recos_nn[:, 0], recos_nn[:, 1], recos_nn[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
